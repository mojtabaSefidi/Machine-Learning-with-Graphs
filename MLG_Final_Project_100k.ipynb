{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mojtabaSefidi/Machine-Learning-with-Graphs/blob/main/MLG_Final_Project_100k.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip ml-100k.zip\n",
        "# !pip uninstall jupyter\n",
        "# !pip install jupyter"
      ],
      "metadata": {
        "id": "2AK7CPIHJ2lq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwlKn2JrXvYo"
      },
      "source": [
        "## Install Essential Packages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHfg4IsV_paR",
        "outputId": "fcff72a7-c3cc-424a-e1d0-bf9ce6e1dca9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eyylEyBAw67k"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch_geometric\n",
        "!pip install -q torch-sparse==0.6.13\n",
        "!pip install -q torch_scatter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcOrS826X3wJ"
      },
      "source": [
        "## Install Essential Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "OCSrkduHlCPt"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import networkx as nx\n",
        "import torch_geometric\n",
        "from torch_geometric.utils import to_networkx\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, GraphConv, SAGEConv, global_add_pool\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric import transforms\n",
        "from torch_geometric.loader import LinkNeighborLoader\n",
        "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import seed\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model"
      ],
      "metadata": {
        "id": "oWb4j2GQ0Mov"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from torch_geometric.loader import LinkNeighborLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import random\n"
      ],
      "metadata": {
        "id": "a8xk67dMCYId"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import seaborn as sn\n",
        "sn.set()\n",
        "\n",
        "def plot_confusion_matrix(confusion_matrix, title='', cmap ='Greens'):\n",
        "    df = pd.DataFrame(confusion_matrix, range(len(confusion_matrix)), range(len(confusion_matrix)))\n",
        "    plt.figure(figsize=(6,4))\n",
        "    if title == '' :\n",
        "        plt.title('Confusion Matrix')\n",
        "    else:\n",
        "        plt.title('Confusion Matrix for' + ' ' + title)\n",
        "    sn.set(font_scale=1)\n",
        "    sn.heatmap(df, annot=True, annot_kws={\"size\": 12},fmt='.0f',cmap=cmap) # font size\n",
        "    plt.ylabel('Actual label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()\n",
        "\n",
        "def save_evaluation_details(report, df, title):\n",
        "  row = []\n",
        "  for item in list(report.values()):\n",
        "    if type(item) == dict:\n",
        "      row.extend(item.values())\n",
        "    else:\n",
        "      row.append(item)\n",
        "  \n",
        "  row.append(title)\n",
        "  return df.append(pd.DataFrame([row], columns=df.columns.values), ignore_index=True)"
      ],
      "metadata": {
        "id": "SqKQ3KDXDL7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(list_train_rmse, list_train_mse, list_val_rmse, list_val_mse, n_epochs, title):\n",
        "    \n",
        "    plt.figure(figsize=(18,8),linewidth = 7, edgecolor=\"whitesmoke\")    \n",
        "    n = n_epochs\n",
        "    \n",
        "    plt.plot(list(range(1, n_epochs+1)), list_train_rmse, color='orange',marker=\".\")\n",
        "    plt.plot(list(range(1, n_epochs+1)), list_train_mse,'b',marker=\".\")\n",
        "    \n",
        "    plt.plot(list(range(1, n_epochs+1)), list_val_rmse,'r')  \n",
        "    plt.plot(list(range(1, n_epochs+1)), list_val_mse,'g')\n",
        "    \n",
        "    plt.legend(['Train RMSE', 'Train MSE','Test RMSE','Test MSE'])\n",
        "    plt.grid(True)\n",
        "    \n",
        "    # plt.gca().set_ylim(0,1)\n",
        "    plt.xlabel(\"Number of Epochs\")\n",
        "    plt.ylabel(\"Value\")\n",
        "    title = 'RMSE & MSE for Train & Validation dataset in ' + title\n",
        "    plt.suptitle(title, size=16, y=0.927)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "u58ez8Rrjjt7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LswIWaVoX901"
      },
      "source": [
        "## Read the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "plfs4IO6DLFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZjGUj-btw3_l"
      },
      "outputs": [],
      "source": [
        "# from ogb.graphproppred import PygGraphPropPredDataset\n",
        "# from torch_geometric.loader import DataLoader\n",
        "\n",
        "# dataset = PygGraphPropPredDataset(name = 'ogbg-molhiv') \n",
        "\n",
        "# split_idx = dataset.get_idx_split() \n",
        "# train_data_loader = DataLoader(dataset[split_idx[\"train\"]], batch_size=32, shuffle=True)\n",
        "# valiation_data_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=32, shuffle=True)\n",
        "# test_data_loader = DataLoader(dataset[split_idx[\"test\"]], batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip /content/MovieLens1M.zip"
      ],
      "metadata": {
        "id": "LSAkq_eHNIKK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# movies_df = pd.read_csv('/content/ml-100k/u.item', sep='|', engine='python', encoding=\"latin-1\",\n",
        "#                         names = ['MovieID', 'Movie Title', 'Release Date', 'video release date','IMDbURL',\n",
        "#                                  'Unknown','Action','Adventure','Animation', 'Childrens','Comedy',\n",
        "#                                  'Crime','Documentary','Drama','Fantasy', 'Film-Noir','Horror',\n",
        "#                                  'Musical','Mystery','Romance','Sci-Fi','Thriller','War','Western'])\n",
        "\n",
        "# rating_df = pd.read_csv('/content/ml-100k/u.data', sep='\\t', engine='python', encoding=\"latin-1\",\n",
        "#                         names=['UserID','MovieID','Rating','Timestamp'])\n",
        "\n",
        "# users_df = pd.read_csv('/content/ml-100k/u.user', sep='|', engine='python', encoding=\"latin-1\",\n",
        "#                        names=['UserID','Gender','Age','Occupation','Zipcode'])\n",
        "\n",
        "# movies_df.to_csv('/content/gdrive/MyDrive/MLG_Final_Project/MovieLens100k/Data/movies_df.csv', index=False)\n",
        "# rating_df.to_csv('/content/gdrive/MyDrive/MLG_Final_Project/MovieLens100k/Data/rating_df.csv', index=False)\n",
        "# users_df.to_csv('/content/gdrive/MyDrive/MLG_Final_Project/MovieLens100k/Data/users_df.csv', index=False)"
      ],
      "metadata": {
        "id": "qFBOl5HrNIHZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# geners = np.array(['Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime', 'Documentary', 'Drama',\n",
        "#                    'Fantasy', 'Film_Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci_Fi', 'Thriller', 'War', 'Western'], dtype=str)\n",
        "\n",
        "# values = list(range(0, len(geners)))\n",
        "# geners2vec = dict(zip(geners, values))\n",
        "\n",
        "# def extract_geners(text, sep='|'):\n",
        "#   return text.split(sep)\n",
        "\n",
        "# def geners2vector(df_geners, maper):\n",
        "#   result = np.zeros((len(df_geners),len(maper)), dtype='int8')\n",
        "#   for index, text in enumerate(df_geners):\n",
        "#     geners = extract_geners(text)\n",
        "#     for gener in geners:\n",
        "#       result[index][maper.get(gener)] = 1\n",
        "  \n",
        "#   return result"
      ],
      "metadata": {
        "id": "Ut7XNDH3exQ4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def year_extractor(text):\n",
        "#   return text[text.rfind('(')+1:text.rfind(')')]\n",
        "\n",
        "def add_average_rating(rating_df, movies_df, Movie_id_col='MovieID', rating_col='Rating'):\n",
        "  \n",
        "  rating_avg = rating_df.groupby(Movie_id_col).mean()[rating_col].round(4).to_dict()\n",
        "  result = [] \n",
        "  for id in movies_df[Movie_id_col]:\n",
        "    result.append(rating_avg.get(id, 0))\n",
        "  movies_df['Average Rating'] = result\n",
        "  return movies_df\n",
        "\n",
        "# Occupation_mapper = { 0: \"other\", 1: \"academic/educator\", 2: \"artist\", 3: \"clerical/admin\",\n",
        "#                      4: \"college/grad student\",5: \"customer service\", 6: \"doctor/health care\",\n",
        "#                      7: \"executive/managerial\", 8: \"farmer\", 9: \"homemaker\", 10: \"K-12 student\",\n",
        "#                      11: \"lawyer\", 12: \"programmer\", 13: \"retired\", 14: \"sales/marketing\",\n",
        "#                      15: \"scientist\", 16: \"self-employed\", 17: \"technician/engineer\",\n",
        "#                      18: \"tradesman/craftsman\", 19: \"unemployed\", 20: \"writer\"}\n",
        "\n",
        "# def code2Occupation(occupation_col, mapper):\n",
        "#   return occupation_col.map(mapper)\n",
        "\n",
        "\n",
        "# def extract_user_feature(users_df):\n",
        "#   scaler = StandardScaler()\n",
        "#   age = scaler.fit_transform(users_df[['Age']])\n",
        "  \n",
        "#   encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "#   occupation = encoder.fit_transform(users_df[['Occupation']]).toarray()\n",
        "#   features = np.hstack((users_df[['Gender']], age, occupation))\n",
        "#   return torch.from_numpy(features).to(torch.float)\n",
        "\n",
        "# def extract_movie_feature(movies_df, mapper):\n",
        "#   scaler = StandardScaler()\n",
        "#   numerical = scaler.fit_transform(movies_df[['year',\t'averge_rating']])\n",
        "  \n",
        "#   categorical = geners2vector(movies_df['Genres'], mapper)\n",
        "#   features = np.hstack((numerical, categorical))\n",
        "#   return torch.from_numpy(features).to(torch.float)\n",
        "\n",
        "def Timestamp2Date(timestamp):\n",
        "  return datetime.utcfromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "def add_age_group(df, age_col='Age'):\n",
        "  bins= [0,20,25,39,60,110]\n",
        "  labels = ['Teenage','Young Adult','Adult', 'Older Adult','Old']\n",
        "  df['AgeGroup'] = pd.cut(df[age_col], bins=bins, labels=labels, right=False)\n",
        "  return df\n",
        "\n",
        "def find_unknowns(movies_df, title_col='Movie Title', movie_id_col='MovieID'):\n",
        "  unknown_movies = movies_df[movies_df[title_col]=='unknown'][movie_id_col]\n",
        "  return unknown_movies\n",
        "\n",
        "def remove_unknows(df, list_unknown_movies, movie_id_col='MovieID'):\n",
        "  return df[~df[movie_id_col].isin(list_unknown_movies)]\n"
      ],
      "metadata": {
        "id": "HBhT-AUneyoW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df = pd.read_csv('/content/gdrive/MyDrive/MLG_Final_Project/MovieLens100k/Data/movies_df.csv')\n",
        "all_ratings_df = pd.read_csv('/content/gdrive/MyDrive/MLG_Final_Project/MovieLens100k/Data/rating_df.csv')\n",
        "\n",
        "users_df = pd.read_csv('/content/gdrive/MyDrive/MLG_Final_Project/MovieLens100k/Data/users_df.csv')\n",
        "movies_df.shape, users_df.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BULzS9YOvpp",
        "outputId": "aa420668-e8bf-47dc-b2b8-c995695613a0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1682, 24), (943, 5))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_unknown_movies = find_unknowns(movies_df)"
      ],
      "metadata": {
        "id": "qqgJNdgd-gxj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_movies_df(movies_df, list_unknown_movies, all_ratings_df):\n",
        "  movies_df = remove_unknows(movies_df, list_unknown_movies)\n",
        "  movies_df.drop(['video release date', 'IMDbURL'], axis=1, inplace=True)\n",
        "  movies_df['Release Date'] = pd.to_datetime(movies_df['Release Date'])\n",
        "  movies_df['Release Year'] = movies_df['Release Date'].dt.year\n",
        "  movies_df['Release Month'] = movies_df['Release Date'].dt.month\n",
        "  movies_df['Release Day'] = movies_df['Release Date'].dt.strftime('%j').apply(int)\n",
        "  movies_df = movies_df.sort_values(by=['Release Date']).reset_index(drop=True)\n",
        "  movies_df = add_average_rating(all_ratings_df, movies_df)\n",
        "  return movies_df\n",
        "\n",
        "movies_df = preprocess_movies_df(movies_df, list_unknown_movies, all_ratings_df)\n",
        "movies_df.tail(2).T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3fRyCELVOvnN",
        "outputId": "88a0ea69-cf05-4d24-a67a-cb2061244c3c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return super().drop(\n",
            "<ipython-input-15-db653e20aac5>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  movies_df['Release Date'] = pd.to_datetime(movies_df['Release Date'])\n",
            "<ipython-input-15-db653e20aac5>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  movies_df['Release Year'] = movies_df['Release Date'].dt.year\n",
            "<ipython-input-15-db653e20aac5>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  movies_df['Release Month'] = movies_df['Release Date'].dt.month\n",
            "<ipython-input-15-db653e20aac5>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  movies_df['Release Day'] = movies_df['Release Date'].dt.strftime('%j').apply(int)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               1679                 1680\n",
              "MovieID                        1432                  315\n",
              "Movie Title      Mighty, The (1998)     Apt Pupil (1998)\n",
              "Release Date    1998-10-09 00:00:00  1998-10-23 00:00:00\n",
              "Unknown                           0                    0\n",
              "Action                            0                    0\n",
              "Adventure                         0                    0\n",
              "Animation                         0                    0\n",
              "Childrens                         0                    0\n",
              "Comedy                            0                    0\n",
              "Crime                             0                    0\n",
              "Documentary                       0                    0\n",
              "Drama                             1                    1\n",
              "Fantasy                           0                    0\n",
              "Film-Noir                         0                    0\n",
              "Horror                            0                    0\n",
              "Musical                           0                    0\n",
              "Mystery                           0                    0\n",
              "Romance                           0                    0\n",
              "Sci-Fi                            0                    0\n",
              "Thriller                          0                    1\n",
              "War                               0                    0\n",
              "Western                           0                    0\n",
              "Release Year                   1998                 1998\n",
              "Release Month                    10                   10\n",
              "Release Day                     282                  296\n",
              "Average Rating                  1.0                  4.1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41a3a798-84d6-423a-819d-ab39946cf2d0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1679</th>\n",
              "      <th>1680</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MovieID</th>\n",
              "      <td>1432</td>\n",
              "      <td>315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Movie Title</th>\n",
              "      <td>Mighty, The (1998)</td>\n",
              "      <td>Apt Pupil (1998)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Release Date</th>\n",
              "      <td>1998-10-09 00:00:00</td>\n",
              "      <td>1998-10-23 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unknown</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Action</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adventure</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Animation</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Childrens</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Comedy</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Crime</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Documentary</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Drama</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fantasy</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Film-Noir</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Horror</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Musical</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mystery</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Romance</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sci-Fi</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Thriller</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>War</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Western</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Release Year</th>\n",
              "      <td>1998</td>\n",
              "      <td>1998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Release Month</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Release Day</th>\n",
              "      <td>282</td>\n",
              "      <td>296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Average Rating</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41a3a798-84d6-423a-819d-ab39946cf2d0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-41a3a798-84d6-423a-819d-ab39946cf2d0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-41a3a798-84d6-423a-819d-ab39946cf2d0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "users_df = add_age_group(users_df)\n",
        "users_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "xDjBiXuTOvki",
        "outputId": "affd5604-aaab-4875-ede2-a944bec180de"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     UserID  Age Gender     Occupation Zipcode     AgeGroup\n",
              "0         1   24      M     technician   85711  Young Adult\n",
              "1         2   53      F          other   94043  Older Adult\n",
              "2         3   23      M         writer   32067  Young Adult\n",
              "3         4   24      M     technician   43537  Young Adult\n",
              "4         5   33      F          other   15213        Adult\n",
              "..      ...  ...    ...            ...     ...          ...\n",
              "938     939   26      F        student   33319        Adult\n",
              "939     940   32      M  administrator   02215        Adult\n",
              "940     941   20      M        student   97229  Young Adult\n",
              "941     942   48      F      librarian   78209  Older Adult\n",
              "942     943   22      M        student   77841  Young Adult\n",
              "\n",
              "[943 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c06e4e0b-fef9-4e08-bd52-789aa575f01a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Occupation</th>\n",
              "      <th>Zipcode</th>\n",
              "      <th>AgeGroup</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>M</td>\n",
              "      <td>technician</td>\n",
              "      <td>85711</td>\n",
              "      <td>Young Adult</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>53</td>\n",
              "      <td>F</td>\n",
              "      <td>other</td>\n",
              "      <td>94043</td>\n",
              "      <td>Older Adult</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "      <td>M</td>\n",
              "      <td>writer</td>\n",
              "      <td>32067</td>\n",
              "      <td>Young Adult</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>24</td>\n",
              "      <td>M</td>\n",
              "      <td>technician</td>\n",
              "      <td>43537</td>\n",
              "      <td>Young Adult</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>33</td>\n",
              "      <td>F</td>\n",
              "      <td>other</td>\n",
              "      <td>15213</td>\n",
              "      <td>Adult</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>938</th>\n",
              "      <td>939</td>\n",
              "      <td>26</td>\n",
              "      <td>F</td>\n",
              "      <td>student</td>\n",
              "      <td>33319</td>\n",
              "      <td>Adult</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>939</th>\n",
              "      <td>940</td>\n",
              "      <td>32</td>\n",
              "      <td>M</td>\n",
              "      <td>administrator</td>\n",
              "      <td>02215</td>\n",
              "      <td>Adult</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>940</th>\n",
              "      <td>941</td>\n",
              "      <td>20</td>\n",
              "      <td>M</td>\n",
              "      <td>student</td>\n",
              "      <td>97229</td>\n",
              "      <td>Young Adult</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>941</th>\n",
              "      <td>942</td>\n",
              "      <td>48</td>\n",
              "      <td>F</td>\n",
              "      <td>librarian</td>\n",
              "      <td>78209</td>\n",
              "      <td>Older Adult</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>942</th>\n",
              "      <td>943</td>\n",
              "      <td>22</td>\n",
              "      <td>M</td>\n",
              "      <td>student</td>\n",
              "      <td>77841</td>\n",
              "      <td>Young Adult</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>943 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c06e4e0b-fef9-4e08-bd52-789aa575f01a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c06e4e0b-fef9-4e08-bd52-789aa575f01a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c06e4e0b-fef9-4e08-bd52-789aa575f01a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_rating_df(ratings_df, list_unknown_movies, extract_details=False):\n",
        "  ratings_df = remove_unknows(ratings_df, list_unknown_movies)\n",
        "  if extract_details:\n",
        "    ratings_df.loc[:,'Timestamp'] = ratings_df.loc[:,'Timestamp'].apply(Timestamp2Date)\n",
        "    ratings_df.sort_values(by='Timestamp', inplace=True)\n",
        "    ratings_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    ratings_df.loc[:,'Timestamp'] = pd.to_datetime(ratings_df.loc[:,'Timestamp'])\n",
        "    ratings_df.loc[:,'Year'] = ratings_df.loc[:,'Timestamp'].dt.year\n",
        "    ratings_df.loc[:,'Month'] = ratings_df.loc[:,'Timestamp'].dt.month\n",
        "    ratings_df.loc[:,'Weekday'] = ratings_df.loc[:,'Timestamp'].dt.weekday\n",
        "    ratings_df.loc[:,'Hour'] = ratings_df.loc[:,'Timestamp'].dt.hour\n",
        "    ratings_df.loc[:,'DayofYear'] = ratings_df.loc[:,'Timestamp'].dt.strftime('%j')\n",
        "  \n",
        "  return ratings_df"
      ],
      "metadata": {
        "id": "Z6VQuqGDOvh7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_train_validation(path, list_unknown_movies, factor=0.5):\n",
        "  df = pd.read_csv(path, sep='\\t', engine='python', encoding=\"latin-1\",\n",
        "                          names=['UserID','MovieID','Rating','Timestamp'])\n",
        "  train_df = pd.DataFrame(columns=['UserID','MovieID','Rating','Timestamp'])\n",
        "  validation_df = pd.DataFrame(columns=['UserID','MovieID','Rating','Timestamp'])\n",
        "  for movie_id in df['MovieID'].unique():\n",
        "    df_temp = df[df['MovieID']== movie_id]\n",
        "    df_temp = df_temp.sort_values('Timestamp')\n",
        "    lenght_window = len(df_temp)\n",
        "    if lenght_window != 1:\n",
        "      half = round(lenght_window * factor)  \n",
        "      train_df = pd.concat([train_df, df_temp.iloc[:half,:]])\n",
        "      validation_df = pd.concat([validation_df, df_temp.iloc[half:,:]])\n",
        "    else: \n",
        "      if len(train_df) > len(validation_df):\n",
        "        validation_df = pd.concat([validation_df, df_temp])\n",
        "      elif len(train_df) < len(validation_df):\n",
        "        train_df = pd.concat([train_df, df_temp])\n",
        "      else:\n",
        "        if random.random() >= 0.5:\n",
        "          train_df = pd.concat([train_df, df_temp])\n",
        "        else:\n",
        "          validation_df = pd.concat([validation_df, df_temp])\n",
        "  train_df = preprocess_rating_df(train_df, list_unknown_movies)\n",
        "  validation_df = preprocess_rating_df(validation_df, list_unknown_movies)\n",
        "  return train_df.reset_index(drop=True), validation_df.reset_index(drop=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "DnZegOtlzH7P"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_test(path, list_unknown_movies):\n",
        "   test_df = pd.read_csv(path, sep='\\t', engine='python', encoding=\"latin-1\",\n",
        "                         names=['UserID','MovieID','Rating','Timestamp'])\n",
        "   test_df = preprocess_rating_df(test_df, list_unknown_movies)\n",
        "   return test_df.reset_index(drop=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "tcXmdFyt7Ad0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_rating_df, validation_rating_df = generate_train_validation('/content/u1.base', list_unknown_movies)\n",
        "test_rating_df = generate_test('/content/u1.test', list_unknown_movies)\n",
        "train_rating_df.shape, validation_rating_df.shape, test_rating_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0IQ8wIW_5gN",
        "outputId": "9fedfd88-ac98-49df-bb51-81d2ae786bd2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((39998, 4), (39999, 4), (19994, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def finalize_dfs(users_df, movies_df,\n",
        "                 train_rating_df, validation_rating_df, test_rating_df,\n",
        "                 user_id_col='UserID', movie_id_col='MovieID'\n",
        "                 ):\n",
        "  \n",
        "  unique_user_id = users_df['UserID'].unique()\n",
        "  unique_user_id = pd.DataFrame(data={\n",
        "      'UserID': unique_user_id,\n",
        "      'mappedID': pd.RangeIndex(len(unique_user_id))\n",
        "      })\n",
        "  userid_mapper = dict(zip(unique_user_id.iloc[:,0], unique_user_id.iloc[:,-1]))\n",
        "  \n",
        "  # print(\"1. Mapping UserID to consecutive values... \")\n",
        "\n",
        "  unique_movie_id = movies_df['MovieID'].unique()\n",
        "  unique_movie_id = pd.DataFrame(data={\n",
        "      'MovieID': unique_movie_id,\n",
        "      'mappedID': pd.RangeIndex(len(unique_movie_id))\n",
        "      })\n",
        "  movieid_mapper = dict(zip(unique_movie_id.iloc[:,0], unique_movie_id.iloc[:,-1]))\n",
        "  # print(\"2. Mapping MovieID to consecutive values... \")\n",
        "\n",
        "  users_df['UserID'] = users_df['UserID'].map(userid_mapper)\n",
        "  users_df = users_df.sort_values(by='UserID').reset_index(drop=True)\n",
        "  movies_df['MovieID'] =  movies_df['MovieID'].map(movieid_mapper)\n",
        "  movies_df = movies_df.sort_values(by='MovieID').reset_index(drop=True)\n",
        "  train_rating_df['UserID'] = train_rating_df['UserID'].map(userid_mapper)\n",
        "  train_rating_df['MovieID'] =  train_rating_df['MovieID'].map(movieid_mapper)\n",
        "  validation_rating_df['UserID'] = validation_rating_df['UserID'].map(userid_mapper)\n",
        "  validation_rating_df['MovieID'] =  validation_rating_df['MovieID'].map(movieid_mapper)\n",
        "  test_rating_df['UserID'] = test_rating_df['UserID'].map(userid_mapper)\n",
        "  test_rating_df['MovieID'] =  test_rating_df['MovieID'].map(movieid_mapper)\n",
        "\n",
        "  users_df = users_df.sort_values(by=user_id_col).reset_index(drop=True)\n",
        "  movies_df = movies_df.sort_values(by=movie_id_col).reset_index(drop=True)\n",
        "  train_rating_df = train_rating_df.sort_values(by=[user_id_col, movie_id_col]).reset_index(drop=True)\n",
        "  validation_rating_df = validation_rating_df.sort_values(by=[user_id_col, movie_id_col]).reset_index(drop=True)\n",
        "  test_rating_df = test_rating_df.sort_values(by=[user_id_col, movie_id_col]).reset_index(drop=True)\n",
        "  return users_df, movies_df, train_rating_df, validation_rating_df, test_rating_df\n",
        "\n",
        "users_df, movies_df, train_rating_df, validation_rating_df, test_rating_df = finalize_dfs(users_df, movies_df,\n",
        "                                                                                          train_rating_df, validation_rating_df,\n",
        "                                                                                          test_rating_df)"
      ],
      "metadata": {
        "id": "MK_yay-a9X2X"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_rating_df"
      ],
      "metadata": {
        "id": "mE5KfSQyE57s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PreProcess_Dfs():\n",
        "  def __init__(self,\n",
        "               movies_df_path,\n",
        "               users_df_path,\n",
        "               ratings_df_path,\n",
        "               train_df_path,\n",
        "               test_df_path,\n",
        "               list_unknown_movies\n",
        "               ):\n",
        "    \n",
        "    self.movies_df = pd.read_csv(movies_df_path)\n",
        "    self.ratings_df_all = pd.read_csv(ratings_df_path)\n",
        "    self.users_df = pd.read_csv(users_df_path)\n",
        "    self.train_df_path = train_df_path\n",
        "    self.test_df_path = test_df_path\n",
        "    self.list_unknown_movies = list_unknown_movies\n",
        "  \n",
        "  def preprocess_movies_df(self):\n",
        "    self.movies_df = remove_unknows(self.movies_df, self.list_unknown_movies)\n",
        "    self.movies_df.drop(['video release date', 'IMDbURL'], axis=1, inplace=True)\n",
        "    self.movies_df['Release Date'] = pd.to_datetime(self.movies_df['Release Date'])\n",
        "    self.movies_df['Release Year'] = self.movies_df['Release Date'].dt.year\n",
        "    self.movies_df['Release Month'] = self.movies_df['Release Date'].dt.month\n",
        "    self.movies_df['Release Day'] = self.movies_df['Release Date'].dt.strftime('%j').apply(int)\n",
        "    self.movies_df = self.movies_df.sort_values(by=['Release Date']).reset_index(drop=True)\n",
        "    self.movies_df = add_average_rating(self.ratings_df_all, self.movies_df)\n",
        "\n",
        "  def preprocess_users_df(self):\n",
        "    self.users_df = add_age_group(self.users_df)\n",
        "\n",
        "  def preprocess_rating_df(self, ratings_df, extract_details=False):\n",
        "    ratings_df = remove_unknows(ratings_df, self.list_unknown_movies)\n",
        "    if extract_details:\n",
        "      ratings_df.loc[:,'Timestamp'] = ratings_df.loc[:,'Timestamp'].apply(Timestamp2Date)\n",
        "      ratings_df.sort_values(by='Timestamp', inplace=True)\n",
        "      ratings_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "      ratings_df.loc[:,'Timestamp'] = pd.to_datetime(ratings_df.loc[:,'Timestamp'])\n",
        "      ratings_df.loc[:,'Year'] = ratings_df.loc[:,'Timestamp'].dt.year\n",
        "      ratings_df.loc[:,'Month'] = ratings_df.loc[:,'Timestamp'].dt.month\n",
        "      ratings_df.loc[:,'Weekday'] = ratings_df.loc[:,'Timestamp'].dt.weekday\n",
        "      ratings_df.loc[:,'Hour'] = ratings_df.loc[:,'Timestamp'].dt.hour\n",
        "      ratings_df.loc[:,'DayofYear'] = ratings_df.loc[:,'Timestamp'].dt.strftime('%j')\n",
        "    \n",
        "    return ratings_df\n",
        "  \n",
        "  def generate_train_validation(self, factor=0.5):\n",
        "    df = pd.read_csv(self.train_df_path, sep='\\t', engine='python', encoding=\"latin-1\",\n",
        "                            names=['UserID','MovieID','Rating','Timestamp'])\n",
        "    train_df = pd.DataFrame(columns=['UserID','MovieID','Rating','Timestamp'])\n",
        "    validation_df = pd.DataFrame(columns=['UserID','MovieID','Rating','Timestamp'])\n",
        "    for movie_id in df['MovieID'].unique():\n",
        "      df_temp = df[df['MovieID']== movie_id]\n",
        "      df_temp = df_temp.sort_values('Timestamp')\n",
        "      lenght_window = len(df_temp)\n",
        "      if lenght_window != 1:\n",
        "        half = round(lenght_window * factor)  \n",
        "        train_df = pd.concat([train_df, df_temp.iloc[:half,:]])\n",
        "        validation_df = pd.concat([validation_df, df_temp.iloc[half:,:]])\n",
        "      else: \n",
        "        if len(train_df) > len(validation_df):\n",
        "          validation_df = pd.concat([validation_df, df_temp])\n",
        "        elif len(train_df) < len(validation_df):\n",
        "          train_df = pd.concat([train_df, df_temp])\n",
        "        else:\n",
        "          if random.random() >= 0.5:\n",
        "            train_df = pd.concat([train_df, df_temp])\n",
        "          else:\n",
        "            validation_df = pd.concat([validation_df, df_temp])\n",
        "    train_df = self.preprocess_rating_df(train_df)\n",
        "    validation_df = preprocess_rating_df(validation_df)\n",
        "    return train_df.reset_index(drop=True), validation_df.reset_index(drop=True)\n",
        "\n",
        "  def generate_test(self):\n",
        "    test_df = pd.read_csv(self.test_df_path, sep='\\t', engine='python', encoding=\"latin-1\",\n",
        "                          names=['UserID','MovieID','Rating','Timestamp'])\n",
        "    test_df = self.preprocess_rating_df(test_df)\n",
        "    return test_df.reset_index(drop=True)\n",
        "\n",
        "  def finalize_dfs(self,\n",
        "                 train_rating_df, validation_rating_df, test_rating_df,\n",
        "                 user_id_col='UserID', movie_id_col='MovieID'\n",
        "                 ):\n",
        "  \n",
        "    unique_user_id = self.users_df['UserID'].unique()\n",
        "    unique_user_id = pd.DataFrame(data={\n",
        "        'UserID': unique_user_id,\n",
        "        'mappedID': pd.RangeIndex(len(unique_user_id))\n",
        "        })\n",
        "    userid_mapper = dict(zip(unique_user_id.iloc[:,0], unique_user_id.iloc[:,-1]))\n",
        "    \n",
        "    # print(\"1. Mapping UserID to consecutive values... \")\n",
        "\n",
        "    unique_movie_id = self.movies_df['MovieID'].unique()\n",
        "    unique_movie_id = pd.DataFrame(data={\n",
        "        'MovieID': unique_movie_id,\n",
        "        'mappedID': pd.RangeIndex(len(unique_movie_id))\n",
        "        })\n",
        "    movieid_mapper = dict(zip(unique_movie_id.iloc[:,0], unique_movie_id.iloc[:,-1]))\n",
        "    # print(\"2. Mapping MovieID to consecutive values... \")\n",
        "\n",
        "    self.users_df['UserID'] = self.users_df['UserID'].map(userid_mapper)\n",
        "    self.users_df = self.users_df.sort_values(by='UserID').reset_index(drop=True)\n",
        "    self.movies_df['MovieID'] =  self.movies_df['MovieID'].map(movieid_mapper)\n",
        "    self.movies_df = self.movies_df.sort_values(by='MovieID').reset_index(drop=True)\n",
        "    train_rating_df['UserID'] = train_rating_df['UserID'].map(userid_mapper)\n",
        "    train_rating_df['MovieID'] =  train_rating_df['MovieID'].map(movieid_mapper)\n",
        "    validation_rating_df['UserID'] = validation_rating_df['UserID'].map(userid_mapper)\n",
        "    validation_rating_df['MovieID'] =  validation_rating_df['MovieID'].map(movieid_mapper)\n",
        "    test_rating_df['UserID'] = test_rating_df['UserID'].map(userid_mapper)\n",
        "    test_rating_df['MovieID'] =  test_rating_df['MovieID'].map(movieid_mapper)\n",
        "\n",
        "    self.users_df = self.users_df.sort_values(by=user_id_col).reset_index(drop=True)\n",
        "    self.movies_df = self.movies_df.sort_values(by=movie_id_col).reset_index(drop=True)\n",
        "    train_rating_df = train_rating_df.sort_values(by=[user_id_col, movie_id_col]).reset_index(drop=True)\n",
        "    validation_rating_df = validation_rating_df.sort_values(by=[user_id_col, movie_id_col]).reset_index(drop=True)\n",
        "    test_rating_df = test_rating_df.sort_values(by=[user_id_col, movie_id_col]).reset_index(drop=True)\n",
        "    return train_rating_df, validation_rating_df, test_rating_df\n",
        "  \n",
        "  def extract_user_feature(self):\n",
        "    scaler = StandardScaler()\n",
        "    age = scaler.fit_transform(self.users_df[['Age']])\n",
        "    \n",
        "    encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "    categorical_df = encoder.fit_transform(users_df[['Occupation', 'Gender']]).toarray()\n",
        "    features = np.hstack((categorical_df, age))\n",
        "    return features\n",
        "\n",
        "  def extract_movie_feature(self, exclude_cols=['MovieID','Movie Title', 'Release Date']):\n",
        "    movies_df = self.movies_df.drop(exclude_cols, axis=1)\n",
        "    scaler = StandardScaler()\n",
        "    movies_df[['Release Year', 'Release Month', 'Average Rating', 'Release Day']] = scaler.fit_transform(\n",
        "        movies_df[['Release Year', 'Release Month', 'Average Rating', 'Release Day']])\n",
        "    features = movies_df.to_numpy()\n",
        "    return features\n",
        "  \n",
        "  def PCA_DR(self, features, precent=0.95):\n",
        "    pca = PCA(precent)\n",
        "    return pca.fit_transform(features)\n",
        "  \n",
        "  def AE_DR(self, features, encoding_dim=8):\n",
        "    AE, encoder = build_AE(encoding_dim = encoding_dim, input_shape= features.shape[-1])\n",
        "    return train_reduce_AE(AE, encoder, features)\n",
        "\n",
        "  def main(self, DR_Approach='PCA'):\n",
        "    print('1. PreProcessing of Movies and users data-frames...')\n",
        "    self.preprocess_movies_df()\n",
        "    self.preprocess_users_df()\n",
        "\n",
        "    print('2. Generate Train/ Validation/ Test data-frames...')\n",
        "    train_df, validation_df = self.generate_train_validation(factor=0.5)\n",
        "    test_df = self.generate_test()\n",
        "    \n",
        "    print('3. PreProcessing of Train/ Validation/ Test data-frames...')\n",
        "    train_df = self.preprocess_rating_df(train_df)\n",
        "    validation_df = self.preprocess_rating_df(validation_df)\n",
        "    test_df = self.preprocess_rating_df(test_df)\n",
        "    \n",
        "    print('4. Finalizing all data-frames...')\n",
        "    train_df, validation_df, test_df = self.finalize_dfs(train_df, validation_df, test_df)\n",
        "    \n",
        "    print('5. Extract users & movies features...')\n",
        "    user_features = self.extract_user_feature()\n",
        "    movie_features = self.extract_movie_feature()\n",
        "\n",
        "    if DR_Approach == 'PCA':\n",
        "      print('6. Reduce dimensionality of features...')\n",
        "      user_features = self.PCA_DR(user_features)\n",
        "      movie_features = self.PCA_DR(movie_features)\n",
        "\n",
        "    elif DR_Approach == 'AE':\n",
        "      print('6. Reduce dimensionality of features...')\n",
        "      user_features = self.AE_DR(user_features)\n",
        "      movie_features = self.AE_DR(movie_features)\n",
        "\n",
        "    print('------------ Finished ------------')\n",
        "    return train_df, validation_df, test_df, user_features, movie_features"
      ],
      "metadata": {
        "id": "6GvODCvaWdEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_user_feature(users_df):\n",
        "  scaler = StandardScaler()\n",
        "  age = scaler.fit_transform(users_df[['Age']])\n",
        "  \n",
        "  encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "  categorical_df = encoder.fit_transform(users_df[['Occupation', 'Gender']]).toarray()\n",
        "  features = np.hstack((categorical_df, age))\n",
        "  return features\n",
        "\n",
        "def extract_movie_feature(movies_df, exclude_cols):\n",
        "  movies_df = movies_df.drop(exclude_cols, axis=1)\n",
        "  scaler = StandardScaler()\n",
        "  movies_df[['Release Year', 'Release Month', 'Average Rating', 'Release Day']] = scaler.fit_transform(\n",
        "      movies_df[['Release Year', 'Release Month', 'Average Rating', 'Release Day']])\n",
        "  features = movies_df.to_numpy()\n",
        "  return features"
      ],
      "metadata": {
        "id": "fzBG182t0BMZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_features = extract_user_feature(users_df)\n",
        "movie_features = extract_movie_feature(movies_df, ['MovieID','Movie Title', 'Release Date'])\n",
        "movie_features.shape, user_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeIi5yYCDG-s",
        "outputId": "1e3b2f60-5372-4fc6-e612-ee04c5ad3f04"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1681, 23), (943, 24))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(0.95)\n",
        "movie_features_reduced_pca = pca.fit_transform(movie_features)\n",
        "user_features_reduced_pca = pca.fit_transform(user_features)\n",
        "movie_features_reduced_pca.shape, user_features_reduced_pca.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xksCPb6AA5si",
        "outputId": "ba74268a-e71d-453f-d991-bdf32a5dfd3f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1681, 11), (943, 14))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_AE(encoding_dim = 8, input_shape= 24):\n",
        "\n",
        "  input_dim = Input(shape = (input_shape, ))\n",
        "\n",
        "  encoded1 = Dense(16, activation = 'relu')(input_dim)\n",
        "  encoded2 = Dense(encoding_dim, activation = 'relu')(encoded1)\n",
        "\n",
        "  decoded1 = Dense(16, activation = 'relu')(encoded2)\n",
        "  decoded2 = Dense(input_shape, activation = 'relu')(decoded1)\n",
        "\n",
        "\n",
        "  autoencoder = Model(inputs = input_dim, outputs = decoded2)\n",
        "  encoder = Model(inputs = input_dim, outputs = encoded2)\n",
        "\n",
        "  autoencoder.compile(optimizer = keras.optimizers.Adadelta(learning_rate=0.05), loss = 'binary_crossentropy')\n",
        "  print(autoencoder.summary())\n",
        "  return autoencoder, encoder"
      ],
      "metadata": {
        "id": "2bM1Q66RzCwK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_reduce_AE(AE, encoder, features, epochs=50, batch_size=16):\n",
        "  print('---------------------------------------Trainig of AE Sarts...')\n",
        "  AE.fit(features, features, epochs=epochs, batch_size=batch_size, shuffle = True, verbose=0)\n",
        "  print('--------------------------------------- Dimensionality Reduction Sarts...')\n",
        "  return encoder.predict(features)\n"
      ],
      "metadata": {
        "id": "3asAKB6l4IGo"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_autoencoder, user_encoder = build_AE(encoding_dim = 8, input_shape= user_features.shape[-1])\n",
        "movie_autoencoder, movie_encoder = build_AE(encoding_dim = 8, input_shape= movie_features.shape[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVVc6Ky9CZ01",
        "outputId": "30e1a614-0344-4918-d9a9-8f5bde07fba2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 24)]              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                400       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                144       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 24)                408       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,088\n",
            "Trainable params: 1,088\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 23)]              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 16)                384       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 16)                144       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 23)                391       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,055\n",
            "Trainable params: 1,055\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_features_reduced_ae = train_reduce_AE(user_autoencoder, user_encoder, user_features)\n",
        "movie_features_reduced_ae = train_reduce_AE(movie_autoencoder, movie_encoder, movie_features)\n",
        "user_features_reduced_ae.shape, movie_features_reduced_ae.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUqNhlvj4oWu",
        "outputId": "e74f43a1-b5f7-4e33-b744-41bcc4db1c45"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------Trainig of AE Sarts:\n",
            "--------------------------------------- Dimensionality Reduction Sarts:\n",
            "30/30 [==============================] - 0s 4ms/step\n",
            "---------------------------------------Trainig of AE Sarts:\n",
            "--------------------------------------- Dimensionality Reduction Sarts:\n",
            "53/53 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((943, 8), (1681, 8))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Build_graphs():\n",
        "  def __init__(self,\n",
        "               train_df,\n",
        "               validation_df,\n",
        "               test_df,\n",
        "               ):\n",
        "    \n",
        "    self.train_df = train_df\n",
        "    self.validation_df = validation_df\n",
        "    self.test_df = test_df\n",
        "  \n",
        "  def generate_edge(self, rating_df, rating_threshold=0):\n",
        "\n",
        "    graph_edges = [[],[]]\n",
        "    edge_weight = []\n",
        "\n",
        "    for userID, movieID, rating in rating_df[['UserID','MovieID','Rating']].itertuples(index=False):\n",
        "      if rating >= rating_threshold:\n",
        "        graph_edges[0].append(userID)\n",
        "        graph_edges[1].append(movieID)\n",
        "        edge_weight.append(rating)\n",
        "      \n",
        "      else:\n",
        "        continue\n",
        "    \n",
        "    return torch.tensor(graph_edges, dtype=torch.long), torch.tensor(edge_weight, dtype=torch.float)\n",
        "\n",
        "  def generate_hetero_dataset(self, data, movies_df, users_df, movie_feature, user_feature, edges, labels):\n",
        "    dataset = HeteroData()\n",
        "\n",
        "    dataset[\"user\"].node_id = torch.tensor(users_df['UserID'].unique().astype(int), dtype=torch.int)\n",
        "    dataset[\"movie\"].node_id = torch.tensor(movies_df['MovieID'].unique().astype(int), dtype=torch.int)\n",
        "    dataset[\"movie\"].x = torch.tensor(movie_feature, dtype=torch.float)\n",
        "    dataset[\"user\"].x = torch.tensor(user_feature, dtype=torch.float)\n",
        "    dataset[\"user\", \"rates\", \"movie\"].edge_index = edges\n",
        "    dataset[\"user\", \"rates\", \"movie\"].edge_label_index = edges\n",
        "    dataset[\"user\", \"rates\", \"movie\"].edge_label = labels\n",
        "\n",
        "    dataset = transforms.ToUndirected()(dataset)\n",
        "    dataset = transforms.NormalizeFeatures()(dataset)\n",
        "    return dataset\n",
        "  \n",
        "  def generate_data_loader(self, dataset):\n",
        "    edge_label_index = dataset[\"user\", \"rates\", \"movie\"].edge_label_index\n",
        "    edge_label = dataset[\"user\", \"rates\", \"movie\"].edge_label\n",
        "    data_loader = LinkNeighborLoader(\n",
        "        data=dataset,\n",
        "        num_neighbors=[20, 10],\n",
        "        neg_sampling_ratio=2.0,\n",
        "        edge_label_index=((\"user\", \"rates\", \"movie\"), edge_label_index),\n",
        "        edge_label=edge_label,\n",
        "        batch_size=32,\n",
        "        shuffle=True\n",
        "        )\n",
        "    return data_loader\n",
        "\n",
        "  def main(self, movies_df, users_df, user_features, movie_features):\n",
        "    \n",
        "    print('1. Extract graph edges and edges labels...')\n",
        "    graph_edges_train, label_train = self.generate_edge(self.train_df)\n",
        "    graph_edges_validation, label_validation = self.generate_edge(self.validation_df)\n",
        "    graph_edges_test, label_test = self.generate_edge(self.test_df)\n",
        "\n",
        "    print('2. Generate Train/ Validation/ Test datasets...')\n",
        "    train_dataset = generate_hetero_dataset(self.train_df, movies_df, users_df, movie_features, user_features, graph_edges_train, label_train)\n",
        "    validation_dataset = generate_hetero_dataset(self.validation_df, movies_df, users_df, movie_features, user_features, graph_edges_validation, label_validation)\n",
        "    test_dataset = generate_hetero_dataset(self.test_df, movie_features, movies_df, users_df, user_features, graph_edges_test, label_test)\n",
        "\n",
        "    \n",
        "    print('3. Convert Train/ Validation/ Test datasets to form of data-loders...')\n",
        "    train_loader = generate_data_loader(train_dataset)\n",
        "    validation_loader = generate_data_loader(validation_dataset)\n",
        "    test_loader = generate_data_loader(test_dataset)\n",
        "    \n",
        "    return train_loader, validation_loader, test_loader\n"
      ],
      "metadata": {
        "id": "Lh9XVskreOFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_edge(rating_df, rating_threshold=0):\n",
        "\n",
        "  graph_edges = [[],[]]\n",
        "  edge_weight = []\n",
        "\n",
        "  for userID, movieID, rating in rating_df[['UserID','MovieID','Rating']].itertuples(index=False):\n",
        "    if rating >= rating_threshold:\n",
        "      graph_edges[0].append(userID)\n",
        "      graph_edges[1].append(movieID)\n",
        "      edge_weight.append(rating)\n",
        "    \n",
        "    else:\n",
        "      continue\n",
        "  \n",
        "  return torch.tensor(graph_edges, dtype=torch.long), torch.tensor(edge_weight, dtype=torch.float)"
      ],
      "metadata": {
        "id": "FFmQO9CsBGuo"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_edges_train, label_train = generate_edge(train_rating_df, rating_threshold=0)\n",
        "graph_edges_validation, label_validation = generate_edge(validation_rating_df, rating_threshold=0)\n",
        "graph_edges_test, label_test = generate_edge(test_rating_df, rating_threshold=0)\n"
      ],
      "metadata": {
        "id": "rKeCQsOd9uYg"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_hetero_dataset(data, movie_feature, user_feature, edges, labels):\n",
        "  dataset = HeteroData()\n",
        "\n",
        "  dataset[\"user\"].node_id = torch.tensor(users_df['UserID'].unique().astype(int), dtype=torch.int)\n",
        "  dataset[\"movie\"].node_id = torch.tensor(movies_df['MovieID'].unique().astype(int), dtype=torch.int)\n",
        "  dataset[\"movie\"].x = torch.tensor(movie_feature, dtype=torch.float)\n",
        "  dataset[\"user\"].x = torch.tensor(user_feature, dtype=torch.float)\n",
        "  dataset[\"user\", \"rates\", \"movie\"].edge_index = edges\n",
        "  dataset[\"user\", \"rates\", \"movie\"].edge_label_index = edges\n",
        "  dataset[\"user\", \"rates\", \"movie\"].edge_label = labels\n",
        "\n",
        "  dataset = transforms.ToUndirected()(dataset)\n",
        "  dataset = transforms.NormalizeFeatures()(dataset)\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "ht7Q_rBwFgZ3"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = generate_hetero_dataset(train_rating_df, movie_features_reduced_ae, user_features_reduced_ae, graph_edges_train, label_train)\n",
        "validation_dataset = generate_hetero_dataset(validation_rating_df, movie_features_reduced_ae, user_features_reduced_ae, graph_edges_validation, label_validation)\n",
        "test_dataset = generate_hetero_dataset(test_rating_df, movie_features_reduced_ae, user_features_reduced_ae, graph_edges_test, label_test)"
      ],
      "metadata": {
        "id": "PP5s6hlvskRQ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(validation_dataset[\"user\", \"rates\", \"movie\"].edge_index).max(), validation_dataset[\"movie\"].x.size(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE3NUe5rGZ3Z",
        "outputId": "d595c342-16f7-4433-d4a0-456953fab878"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(1680), 1681)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_data_loader(dataset):\n",
        "  edge_label_index = dataset[\"user\", \"rates\", \"movie\"].edge_label_index\n",
        "  edge_label = dataset[\"user\", \"rates\", \"movie\"].edge_label\n",
        "  data_loader = LinkNeighborLoader(\n",
        "      data=dataset,\n",
        "      num_neighbors=[20, 10],\n",
        "      neg_sampling_ratio=2.0,\n",
        "      edge_label_index=((\"user\", \"rates\", \"movie\"), edge_label_index),\n",
        "      edge_label=edge_label,\n",
        "      batch_size=32,\n",
        "      shuffle=True\n",
        "      )\n",
        "  return data_loader"
      ],
      "metadata": {
        "id": "kyndxnfgDg9r"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = generate_data_loader(train_dataset)\n",
        "validation_loader = generate_data_loader(validation_dataset)\n",
        "test_loader = generate_data_loader(test_dataset)"
      ],
      "metadata": {
        "id": "DZtsZ8NyVar_"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import SAGEConv, to_hetero\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.conv4 = SAGEConv(hidden_channels, hidden_channels)\n",
        "    \n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv4(x, edge_index)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class Classifier(torch.nn.Module):\n",
        "    def forward(self, x_user, x_movie, edge_label_index):\n",
        "\n",
        "        edge_feat_user = x_user[edge_label_index[0]]\n",
        "        edge_feat_movie = x_movie[edge_label_index[1]]\n",
        "\n",
        "        return (edge_feat_user * edge_feat_movie).sum(dim=-1)\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, data, hidden_channels, user_features_dim, movie_features_dim):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.user_lin = torch.nn.Linear(user_features_dim, hidden_channels)\n",
        "        self.movie_lin = torch.nn.Linear(movie_features_dim, hidden_channels)\n",
        "        self.user_emb = torch.nn.Embedding(data[\"user\"].num_nodes, hidden_channels)\n",
        "        self.movie_emb = torch.nn.Embedding(data[\"movie\"].num_nodes, hidden_channels)\n",
        "\n",
        "        self.gnn = GNN(hidden_channels)\n",
        "\n",
        "        self.gnn = to_hetero(self.gnn, metadata=data.metadata())\n",
        "        self.classifier = Classifier()\n",
        "    \n",
        "    def forward(self, data):\n",
        "        x_dict = {\n",
        "          \"user\": self.user_lin(data[\"user\"].x) + self.user_emb(data[\"user\"].node_id),\n",
        "          \"movie\": self.movie_lin(data[\"movie\"].x) + self.movie_emb(data[\"movie\"].node_id),\n",
        "        } \n",
        "\n",
        "        x_dict = self.gnn(x_dict, data.edge_index_dict)\n",
        "        pred = self.classifier(\n",
        "            x_dict[\"user\"],\n",
        "            x_dict[\"movie\"],\n",
        "            data[\"user\", \"rates\", \"movie\"].edge_label_index,\n",
        "        )\n",
        "        return pred\n",
        "        \n",
        "model = Model(data=train_dataset , hidden_channels=32, user_features_dim=8, movie_features_dim=8)\n",
        "model"
      ],
      "metadata": {
        "id": "ztVe6WBhHff0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82f41a49-d61a-4bfd-e40b-845efbf9c7ef"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (user_lin): Linear(in_features=8, out_features=32, bias=True)\n",
              "  (movie_lin): Linear(in_features=8, out_features=32, bias=True)\n",
              "  (user_emb): Embedding(943, 32)\n",
              "  (movie_emb): Embedding(1681, 32)\n",
              "  (gnn): GraphModule(\n",
              "    (conv1): ModuleDict(\n",
              "      (user__rates__movie): SAGEConv(32, 32, aggr=mean)\n",
              "      (movie__rev_rates__user): SAGEConv(32, 32, aggr=mean)\n",
              "    )\n",
              "    (conv2): ModuleDict(\n",
              "      (user__rates__movie): SAGEConv(32, 32, aggr=mean)\n",
              "      (movie__rev_rates__user): SAGEConv(32, 32, aggr=mean)\n",
              "    )\n",
              "    (conv3): ModuleDict(\n",
              "      (user__rates__movie): SAGEConv(32, 32, aggr=mean)\n",
              "      (movie__rev_rates__user): SAGEConv(32, 32, aggr=mean)\n",
              "    )\n",
              "    (conv4): ModuleDict(\n",
              "      (user__rates__movie): SAGEConv(32, 32, aggr=mean)\n",
              "      (movie__rev_rates__user): SAGEConv(32, 32, aggr=mean)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Classifier()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# del user_autoencoder, user_encoder, movie_autoencoder, movie_encoder, pca"
      ],
      "metadata": {
        "id": "ibblIz44EMSn"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Learning_Evaluation(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        learning_rate=0.01,\n",
        "        best_results=[np.Inf, np.Inf, np.Inf, np.Inf, np.Inf],\n",
        "        ):\n",
        "      \n",
        "      super().__init__()\n",
        "      self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "      self.model = model.to(self.device)\n",
        "      self.optimizer = torch.optim.SGD(self.model.parameters(), lr=learning_rate)\n",
        "      self.criterion = torch.nn.MSELoss()\n",
        "      self.best_results = best_results\n",
        "    \n",
        "    def train(self, data_loader):\n",
        "        self.model.train()\n",
        "\n",
        "        for data in data_loader:\n",
        "            out = self.model(data)\n",
        "            label = data[\"user\", \"rates\", \"movie\"].edge_label\n",
        "            loss = self.criterion(out, label)\n",
        "            # loss = F.mse_loss(pred, ground_truth)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "    # def evaluate(self, data_loader):\n",
        "    #     self.model.eval()\n",
        "        \n",
        "    #     predicted = []\n",
        "    #     labels = []\n",
        "    #     total_loss = total_sample = 0\n",
        "        \n",
        "    #     for data in data_loader:\n",
        "    #       with torch.no_grad():\n",
        "    #         data.to(device)\n",
        "    #         out = model(data)\n",
        "    #         label = data[\"user\", \"rates\", \"movie\"].edge_label\n",
        "    #         total_loss += self.criterion(out, label) * len(out)\n",
        "    #         # total_loss += F.binary_cross_entropy_with_logits(out, label)\n",
        "    #         total_sample += len(out)\n",
        "    #         predicted.append(out)\n",
        "    #         labels.append(label)\n",
        "            \n",
        "    #     predicted = torch.cat(predicted, dim=0).cpu().numpy()\n",
        "    #     labels = torch.cat(labels, dim=0).cpu().numpy()\n",
        "    #     # auc = roc_auc_score(labels, predicted)\n",
        "\n",
        "    #     return total_loss/ total_sample\n",
        "\n",
        "    def train_model(self, train_data_loader, validation_data_loader, n_epochs=15, best_model_saving_path='best_model.pth'):\n",
        "      \n",
        "      list_train_mse, list_train_rmse, list_validation_rmse, list_validation_mse = [], [], [], []\n",
        "      print('Train and Evaluation started...')\n",
        "      for epoch in range(1, n_epochs+1):\n",
        "          self.train(train_data_loader)\n",
        "          \n",
        "          # train_auc, train_loss = self.evaluate(train_data_loader)\n",
        "          _ , _ , train_rmse_loss, train_mse_loss = self.evaluate(train_data_loader)\n",
        "          list_train_mse.append(train_mse_loss)\n",
        "          list_train_rmse.append(train_rmse_loss)\n",
        "          \n",
        "          _ , _ , validation_rmse_loss, validation_mse_loss = self.evaluate(validation_data_loader)\n",
        "          list_validation_mse.append(validation_mse_loss)\n",
        "          list_validation_rmse.append(validation_rmse_loss)\n",
        "          \n",
        "          if self.best_results[-2] > validation_mse_loss :\n",
        "            self.best_results[0] = epoch\n",
        "            self.best_results[1], self.best_results[2] = train_mse_loss, train_rmse_loss\n",
        "            self.best_results[-2], self.best_results[-1] = validation_mse_loss, validation_rmse_loss\n",
        "            torch.save(model, best_model_saving_path)\n",
        "\n",
        "\n",
        "          # print(f'Epoch: {epoch:03d}, Train ROC-AUC: {train_auc:.4f}, Train Loss: {train_loss:.4f}, Validation ROC-AUC: {validation_auc:.4f}, Validation Loss: {validation_loss:.4f}')\n",
        "          print(f'Epoch: {epoch:03d}, Train MSE: {train_mse_loss:.4f}, Train RMSE: {train_rmse_loss:.4f}, Validation MSE: {validation_mse_loss:.4f}, Validation RMSE: {validation_rmse_loss:.4f}')\n",
        "      \n",
        "      print('---------------------------------------------------')\n",
        "      print('Train and Evaluation finished...')\n",
        "      print(f'Best Results of the model : Epoch: {self.best_results[0]:03d}, Train RMSE: {self.best_results[2]:.4f}, Validation RMSE: {self.best_results[-1]:.4f}')\n",
        "      print(f'Model weights restored from epoch: {self.best_results[0]:03d}')\n",
        "      return list_train_mse, list_train_rmse, list_validation_rmse, list_validation_mse\n",
        "\n",
        "    def evaluate(self, data_loder, best_model_path=None):\n",
        "      self.model.eval()\n",
        "      \n",
        "      if not best_model_path is None:\n",
        "        model = torch.load(best_model_path)\n",
        "      else:\n",
        "        model = self.model\n",
        "      predicted = []\n",
        "      labels = []\n",
        "      for data in data_loder:\n",
        "          with torch.no_grad():\n",
        "              data.to(self.device)\n",
        "              predicted.append(model(data))\n",
        "              labels.append(data[\"user\", \"rates\", \"movie\"].edge_label)\n",
        "\n",
        "      predicted = torch.cat(predicted, dim=0).cpu().numpy()\n",
        "      labels = torch.cat(labels, dim=0).cpu().numpy()\n",
        "      rmse = mean_squared_error(labels, predicted, squared=False)\n",
        "      mse = mean_squared_error(labels, predicted, squared=True)\n",
        "\n",
        "      return labels, predicted, rmse, mse\n",
        "\n",
        "      \n",
        "      "
      ],
      "metadata": {
        "id": "-S_c-jAzaYug"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/gdrive/MyDrive/MLG_Final_Project/MovieLens100k/"
      ],
      "metadata": {
        "id": "ByQFdnd3x3rk"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_datasets = [('u1.Base', 'u1.Test'),('u2.Base', 'u2.Test'),\n",
        "                 ('u3.Base', 'u3.Test'),('u4.Base', 'u4.Test'),\n",
        "                 ('u5.Base', 'u5.Test')\n",
        "                 ]\n",
        "\n",
        "DR_Approach='PCA'\n",
        "learning_rate=0.05\n",
        "n_epochs = 50\n",
        "\n",
        "report_df = pd.DataFrame(columns=['precision_0','recall_0','f1-score_0','support_0',\n",
        "                           'precision_1','recall_1','f1-score_1','support_1',\n",
        "                           'accuracy', 'precision_macro','recall_macro','f1-score_macro','support_macro',\n",
        "                           'precision_weighted','recall_weighted','f1-score_weighted','support_weighted', 'title'\n",
        "                           ])\n",
        "\n",
        "train_mse_all, train_rmse_all, validation_rmse_all, validation_mse_all, test_mse_all, test_rmse_all  = [], [], [], [], [], []\n",
        "predictions, labels = [], []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "I-SRrpUnyTWC",
        "outputId": "08675c69-f7ee-4303-c1f2-cc243139b136"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Data/u1.Base'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "for i, data_pahts in enumerate(list_datasets):\n",
        "    print('--------------------- Working on split %d started...' %(i+1))\n",
        "    preprocessor = PreProcess_Dfs(movies_df_path = 'Data/movies_df.csv',\n",
        "                                  users_df_path = 'Data/users_df.csv',\n",
        "                                  ratings_df_path = 'Data/rating_df.csv',\n",
        "                                  train_df_path = 'Data/'+ data_pahts[0] ,\n",
        "                                  test_df_path = 'Data/'+ data_pahts[0] ,\n",
        "                                  list_unknown_movies= list_unknown_movies)\n",
        "    \n",
        "    print('1) Pre-processing...')\n",
        "    train_df, validation_df, test_df, user_features, movie_features = preprocessor.main(DR_Approach=DR_Approach)\n",
        "    graph_generator = Build_graphs(train_df,\n",
        "                                   validation_df,\n",
        "                                   test_df)\n",
        "    print('2) Convert to graph...')\n",
        "    train_loader, validation_loader, test_loader = graph_generator.main(preprocessor.movies_df, preprocessor.users_df,\n",
        "                                                                        user_features, movie_features)\n",
        "    print('3) Model Training...')\n",
        "    experiment = Learning_Evaluation(model, learning_rate=learning_rate)\n",
        "    model_path = 'best_model_' + str(i+1) + '.pth'\n",
        "    list_train_mse, list_train_rmse, list_validation_rmse, list_validation_mse = experiment.train_model(train_loader, validation_loader,\n",
        "                                                                                                        n_epochs=n_epochs,\n",
        "                                                                                                        best_model_saving_path=model_path)\n",
        "    \n",
        "    train_mse_all.append(list_train_mse)\n",
        "    train_rmse_all.append(list_train_rmse)\n",
        "    validation_rmse_all.append(list_validation_rmse)\n",
        "    validation_mse_all.append(list_validation_mse)\n",
        "    \n",
        "    print('4) Model Evaluation...')\n",
        "    results = experiment.evaluate(test_loader)\n",
        "    labels.append(results[0])\n",
        "    predictions.append(results[1]), \n",
        "    test_rmse_all.append(results[-2])\n",
        "    test_mse_all.append(results[-1])\n",
        "\n",
        "    title = 'split'+ (i+1)\n",
        "    \n",
        "    plot_history(list_train_rmse, list_train_mse, list_validation_rmse, list_validation_mse, n_epochs, title)\n",
        "\n",
        "    l = np.where(results[0]>=3, 1, 0)\n",
        "    p = np.where(results[1]>=3, 1, 0)\n",
        "    plot_confusion_matrix(confusion_matrix(l, p), title=title, cmap ='Greens')\n",
        "    print(classification_report(l, p))\n",
        "    report = classification_report(l, p, output_dict=True)\n",
        "    save_evaluation_details(report, report_df, title)\n",
        "\n",
        "\n",
        "    print('--------------------- Working on split %d finished...' %(i+1))\n"
      ],
      "metadata": {
        "id": "FK2lhpB_utsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment = Learning_Evaluation(model, learning_rate=0.05)\n",
        "list_train_mse, list_train_rmse, list_validation_rmse, list_validation_mse = experiment.train_model(train_loader, validation_loader, n_epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2olW2XL4eMqc",
        "outputId": "12fb6b28-bbdc-4e70-d3b5-dcdef12490c7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train and Evaluation started...\n",
            "Epoch: 001, Train MSE: 1.7960, Train RMSE: 1.3402, Validation MSE: 2.2957, Validation RMSE: 1.5152\n",
            "Epoch: 002, Train MSE: 1.7467, Train RMSE: 1.3216, Validation MSE: 2.3935, Validation RMSE: 1.5471\n",
            "Epoch: 003, Train MSE: 1.6505, Train RMSE: 1.2847, Validation MSE: 2.3081, Validation RMSE: 1.5192\n",
            "Epoch: 004, Train MSE: 1.5629, Train RMSE: 1.2502, Validation MSE: 2.1518, Validation RMSE: 1.4669\n",
            "Epoch: 005, Train MSE: 1.5427, Train RMSE: 1.2420, Validation MSE: 2.1382, Validation RMSE: 1.4623\n",
            "Epoch: 006, Train MSE: 1.5334, Train RMSE: 1.2383, Validation MSE: 2.3987, Validation RMSE: 1.5488\n",
            "Epoch: 007, Train MSE: 1.5927, Train RMSE: 1.2620, Validation MSE: 2.0371, Validation RMSE: 1.4273\n",
            "Epoch: 008, Train MSE: 1.4897, Train RMSE: 1.2205, Validation MSE: 2.1045, Validation RMSE: 1.4507\n",
            "Epoch: 009, Train MSE: 1.4666, Train RMSE: 1.2110, Validation MSE: 2.0574, Validation RMSE: 1.4343\n",
            "Epoch: 010, Train MSE: 1.4643, Train RMSE: 1.2101, Validation MSE: 2.1090, Validation RMSE: 1.4522\n",
            "Epoch: 011, Train MSE: 1.4594, Train RMSE: 1.2081, Validation MSE: 2.1770, Validation RMSE: 1.4755\n",
            "Epoch: 012, Train MSE: 1.4489, Train RMSE: 1.2037, Validation MSE: 2.1201, Validation RMSE: 1.4561\n",
            "Epoch: 013, Train MSE: 1.4252, Train RMSE: 1.1938, Validation MSE: 2.0551, Validation RMSE: 1.4336\n",
            "Epoch: 014, Train MSE: 1.4346, Train RMSE: 1.1977, Validation MSE: 2.0577, Validation RMSE: 1.4345\n",
            "Epoch: 015, Train MSE: 1.3955, Train RMSE: 1.1813, Validation MSE: 2.0363, Validation RMSE: 1.4270\n",
            "Epoch: 016, Train MSE: 1.4101, Train RMSE: 1.1875, Validation MSE: 2.0413, Validation RMSE: 1.4287\n",
            "Epoch: 017, Train MSE: 1.4080, Train RMSE: 1.1866, Validation MSE: 2.0182, Validation RMSE: 1.4206\n",
            "Epoch: 018, Train MSE: 1.4049, Train RMSE: 1.1853, Validation MSE: 2.0597, Validation RMSE: 1.4352\n",
            "Epoch: 019, Train MSE: 1.3750, Train RMSE: 1.1726, Validation MSE: 2.1065, Validation RMSE: 1.4514\n",
            "Epoch: 020, Train MSE: 1.3966, Train RMSE: 1.1818, Validation MSE: 2.1439, Validation RMSE: 1.4642\n",
            "Epoch: 021, Train MSE: 1.3512, Train RMSE: 1.1624, Validation MSE: 2.0049, Validation RMSE: 1.4160\n",
            "Epoch: 022, Train MSE: 1.3614, Train RMSE: 1.1668, Validation MSE: 2.0152, Validation RMSE: 1.4196\n",
            "Epoch: 023, Train MSE: 1.3748, Train RMSE: 1.1725, Validation MSE: 2.1000, Validation RMSE: 1.4491\n",
            "Epoch: 024, Train MSE: 1.3563, Train RMSE: 1.1646, Validation MSE: 2.0103, Validation RMSE: 1.4178\n",
            "Epoch: 025, Train MSE: 1.3484, Train RMSE: 1.1612, Validation MSE: 1.9609, Validation RMSE: 1.4003\n",
            "Epoch: 026, Train MSE: 1.3445, Train RMSE: 1.1595, Validation MSE: 2.0154, Validation RMSE: 1.4196\n",
            "Epoch: 027, Train MSE: 1.3478, Train RMSE: 1.1609, Validation MSE: 2.0175, Validation RMSE: 1.4204\n",
            "Epoch: 028, Train MSE: 1.3431, Train RMSE: 1.1589, Validation MSE: 1.9819, Validation RMSE: 1.4078\n",
            "Epoch: 029, Train MSE: 1.3251, Train RMSE: 1.1511, Validation MSE: 2.0136, Validation RMSE: 1.4190\n",
            "Epoch: 030, Train MSE: 1.3183, Train RMSE: 1.1482, Validation MSE: 2.0207, Validation RMSE: 1.4215\n",
            "Epoch: 031, Train MSE: 1.3517, Train RMSE: 1.1626, Validation MSE: 2.0783, Validation RMSE: 1.4416\n",
            "Epoch: 032, Train MSE: 1.3118, Train RMSE: 1.1453, Validation MSE: 2.0167, Validation RMSE: 1.4201\n",
            "Epoch: 033, Train MSE: 1.3194, Train RMSE: 1.1486, Validation MSE: 2.0862, Validation RMSE: 1.4444\n",
            "Epoch: 034, Train MSE: 1.3520, Train RMSE: 1.1628, Validation MSE: 2.0899, Validation RMSE: 1.4456\n",
            "Epoch: 035, Train MSE: 1.3009, Train RMSE: 1.1406, Validation MSE: 1.9687, Validation RMSE: 1.4031\n",
            "Epoch: 036, Train MSE: 1.3099, Train RMSE: 1.1445, Validation MSE: 2.0931, Validation RMSE: 1.4468\n",
            "Epoch: 037, Train MSE: 1.3350, Train RMSE: 1.1554, Validation MSE: 1.9918, Validation RMSE: 1.4113\n",
            "Epoch: 038, Train MSE: 1.3199, Train RMSE: 1.1489, Validation MSE: 1.9585, Validation RMSE: 1.3995\n",
            "Epoch: 039, Train MSE: 1.2819, Train RMSE: 1.1322, Validation MSE: 1.9442, Validation RMSE: 1.3944\n",
            "Epoch: 040, Train MSE: 1.2945, Train RMSE: 1.1378, Validation MSE: 1.9653, Validation RMSE: 1.4019\n",
            "Epoch: 041, Train MSE: 1.3095, Train RMSE: 1.1443, Validation MSE: 1.9824, Validation RMSE: 1.4080\n",
            "Epoch: 042, Train MSE: 1.2756, Train RMSE: 1.1294, Validation MSE: 1.9889, Validation RMSE: 1.4103\n",
            "Epoch: 043, Train MSE: 1.2972, Train RMSE: 1.1390, Validation MSE: 2.0021, Validation RMSE: 1.4150\n",
            "Epoch: 044, Train MSE: 1.2810, Train RMSE: 1.1318, Validation MSE: 1.9663, Validation RMSE: 1.4023\n",
            "Epoch: 045, Train MSE: 1.2658, Train RMSE: 1.1251, Validation MSE: 2.0186, Validation RMSE: 1.4208\n",
            "Epoch: 046, Train MSE: 1.2659, Train RMSE: 1.1251, Validation MSE: 1.9573, Validation RMSE: 1.3990\n",
            "Epoch: 047, Train MSE: 1.2854, Train RMSE: 1.1338, Validation MSE: 1.9875, Validation RMSE: 1.4098\n",
            "Epoch: 048, Train MSE: 1.2537, Train RMSE: 1.1197, Validation MSE: 2.0195, Validation RMSE: 1.4211\n",
            "Epoch: 049, Train MSE: 1.2813, Train RMSE: 1.1320, Validation MSE: 2.0296, Validation RMSE: 1.4247\n",
            "Epoch: 050, Train MSE: 1.2478, Train RMSE: 1.1171, Validation MSE: 1.9451, Validation RMSE: 1.3947\n",
            "---------------------------------------------------\n",
            "Train and Evaluation finished...\n",
            "Best Results of the model : Epoch: 039, Train RMSE: 1.1322, Validation RMSE: 1.3944\n",
            "Model weights restored from epoch: 039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label, pred, rmse, mse = experiment.evaluate(test_loader)"
      ],
      "metadata": {
        "id": "4r9K0Mlyx8RC"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y6fjPNRB3iBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_squared_error(label, pred, squared=False), mean_squared_error(label, pred, squared=True)\n"
      ],
      "metadata": {
        "id": "gX6S2pCYx8Oj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56aedc9c-347a-4552-e08a-468cda2efb31"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.2067213, 1.4561764)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l = np.where(label>=3, 1, 0)\n",
        "p = np.where(pred>=3, 1, 0)\n",
        "print(classification_report(l, p))\n",
        "\n",
        "plot_confusion_matrix(confusion_matrix(l, p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "tQUCxfDJD7R6",
        "outputId": "782686b4-5bc7-4733-8808-bbe94c2a3c67"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.97      0.87     43571\n",
            "           1       0.81      0.31      0.45     16411\n",
            "\n",
            "    accuracy                           0.79     59982\n",
            "   macro avg       0.80      0.64      0.66     59982\n",
            "weighted avg       0.79      0.79      0.76     59982\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = []\n",
        "labels = []\n",
        "i=0\n",
        "for sampled_data in tqdm.tqdm(validation_loader):\n",
        "    with torch.no_grad():\n",
        "        sampled_data.to(device)\n",
        "        predicted.append(model(sampled_data))\n",
        "        labels.append(sampled_data[\"user\", \"rates\", \"movie\"].edge_label)\n",
        "\n",
        "predicted = torch.cat(predicted, dim=0).cpu().numpy()\n",
        "labels = torch.cat(labels, dim=0).cpu().numpy()\n",
        "# auc = roc_auc_score(labels, predicted)\n",
        "# predicted, labels\n",
        "print()\n",
        "# print(f\"Test AUC: {auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "0xL5X4RVhe4R",
        "outputId": "fc51b514-9c4b-4ec9-9d78-426ca40a60d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/625 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-6fb4082e4775>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msampled_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msampled_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/loader/base.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/loader/link_loader.py\u001b[0m in \u001b[0;36mfilter_fn\u001b[0;34m(self, out)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHeteroSamplerOutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHeteroData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                 data = filter_hetero_data(self.data, out.node, out.row,\n\u001b[0m\u001b[1;32m    207\u001b[0m                                           \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                                           self.link_sampler.edge_permutation)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/loader/utils.py\u001b[0m in \u001b[0;36mfilter_hetero_data\u001b[0;34m(data, node_dict, row_dict, col_dict, edge_dict, perm_dict)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         filter_node_store_(data[node_type], out[node_type],\n\u001b[0m\u001b[1;32m    153\u001b[0m                            node_dict[node_type])\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/loader/utils.py\u001b[0m in \u001b[0;36mfilter_node_store_\u001b[0;34m(store, out_store, index)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cat_dim__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mout_store\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/loader/utils.py\u001b[0m in \u001b[0;36mindex_select\u001b[0;34m(value, index, dim)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "mean_squared_error(labels, predicted, squared=False), mean_squared_error(labels, predicted, squared=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "aJb38TjBhe1s",
        "outputId": "e401ead0-65aa-4daa-a57b-266895e67a63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-4a20ae6e2117>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;36m0.825\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \"\"\"\n\u001b[0;32m--> 438\u001b[0;31m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \"\"\"\n\u001b[1;32m     94\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    803\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    806\u001b[0m                 \u001b[0;34m\"Found array with %d sample(s) (shape=%s) while a\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m                 \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l = np.where(labels>=3, 1, 0)\n",
        "p = np.where(predicted>=3, 1, 0)\n",
        "print(classification_report(l, p))"
      ],
      "metadata": {
        "id": "1_dzf87Khey2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1rKrSCpzkLZIz8Yno5n3a",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}