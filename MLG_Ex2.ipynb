{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNyb1cCgAu93quJLuLFn7WX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mojtabaSefidi/Machine-Learning-with-Graphs/blob/main/MLG_Ex2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Essential Packages"
      ],
      "metadata": {
        "id": "lwlKn2JrXvYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\n",
        "!pip install -q torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyylEyBAw67k",
        "outputId": "51fff502-1c54-44eb-91df-ce5346cfa569"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 6.9 MB/s \n",
            "\u001b[?25h  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 467 kB 6.8 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Essential Libraries"
      ],
      "metadata": {
        "id": "FcOrS826X3wJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OCSrkduHlCPt"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import networkx as nx\n",
        "import torch_geometric\n",
        "from torch_geometric.utils import to_networkx\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.transforms import NormalizeFeatures"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read the Dataset"
      ],
      "metadata": {
        "id": "LswIWaVoX901"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Planetoid(root='/tmp/Citeseer', name='Citeseer')"
      ],
      "metadata": {
        "id": "ZjGUj-btw3_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vx_sPIHyUM-F",
        "outputId": "76ec8900-8cae-4621-8ad5-1fdbb6d1f706"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1 : Dataset Details"
      ],
      "metadata": {
        "id": "r6RTprJLYaMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Information_Extaction(dataset):\n",
        "  print('There is %d graph in the dataset.' %len(dataset))\n",
        "  print('The graph has %d nodes.' %dataset[0].num_nodes)\n",
        "  print('The graph has %d edges.' %dataset[0].num_edges)\n",
        "  print('Each node has %d features.' %dataset[0].num_features)\n",
        "  print('These are %d classes.'  %dataset.num_classes)\n",
        "  print(\"The Average degree for each node is %d.\" %round((2*dataset[0].num_edges) / (dataset[0].num_nodes),4))\n",
        "  print('There are %d training nodes in the dataset.' %dataset[0].train_mask.sum().item())\n",
        "  return"
      ],
      "metadata": {
        "id": "j3FopRyV1w_g"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Information_Extaction(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CAhlj3W4MSK",
        "outputId": "5d85fb12-0be1-4b35-e7f3-b02174b69c2f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There is 1 graph in the dataset.\n",
            "The graph has 2708 nodes.\n",
            "The graph has 10556 edges.\n",
            "Each node has 1433 features.\n",
            "These are 7 classes.\n",
            "The Average degree for each node is 7.\n",
            "There are 140 training nodes in the dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_edges(dataset,node_index=1028)"
      ],
      "metadata": {
        "id": "vSBuLySXGzhk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "418b545a-eeac-4cbe-d843-03bacdbb1250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1028, 1557],\n",
              "        [1028, 2320],\n",
              "        [1028, 2605]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4 : Graph visualization"
      ],
      "metadata": {
        "id": "mbhRVaMVbvkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize_graph(dataset[0],50)"
      ],
      "metadata": {
        "id": "5m2l3pzlbUb8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Additional Libraries for GNN"
      ],
      "metadata": {
        "id": "rp3WywYMcZLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear\n",
        "from torch_geometric.nn import GCNConv"
      ],
      "metadata": {
        "id": "2ptUWeUbIfBP"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5 : GCN Implementation"
      ],
      "metadata": {
        "id": "my1bL4h1gFaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class GCN(torch.nn.Module):\n",
        "#     def __init__(\n",
        "#         self,\n",
        "#         dataset,\n",
        "#         hidden_channel=256,\n",
        "#         learning_rate=0.01,\n",
        "#         min_valid_loss = np.inf,\n",
        "        \n",
        "        \n",
        "#         ):\n",
        "      \n",
        "#         super().__init__()\n",
        "#         self.conv1 = GCNConv(dataset.num_node_features, hidden_channel)\n",
        "#         self.conv2 = GCNConv(hidden_channel, hidden_channel)\n",
        "#         self.classifier = Linear(hidden_channel, dataset.num_classes)\n",
        "        \n",
        "#         device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#         self.data = dataset[0].to(device)\n",
        "#         self.optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "#         self.criterion = torch.nn.CrossEntropyLoss()\n",
        "#         self.min_valid_loss = min_valid_loss\n",
        "\n",
        "#     def forward(self, data):\n",
        "#         x, edge_index = data.x, data.edge_index\n",
        "\n",
        "#         x = self.conv1(x, edge_index)\n",
        "#         x = torch.tanh(x)\n",
        "#         x = F.dropout(x, p=0.5, training=self.training)\n",
        "#         x = self.conv2(x, edge_index)\n",
        "#         x = torch.tanh(x)\n",
        "#         return self.classifier(x)\n",
        "\n",
        "#     def training(self):\n",
        "#           save_model_flag = False\n",
        "#           model.train()\n",
        "#           self.optimizer.zero_grad()\n",
        "#           out = model(self.data)\n",
        "#           train_loss = self.criterion(out[self.data.train_mask], self.data.y[self.data.train_mask])\n",
        "#           validation_loss = self.criterion(out[self.data.val_mask], self.data.y[self.data.val_mask])\n",
        "#           if self.min_valid_loss > validation_loss:\n",
        "#               save_model_flag = True\n",
        "#           train_loss.backward()\n",
        "#           self.optimizer.step()\n",
        "\n",
        "#           return train_loss, validation_loss, save_model_flag \n",
        "\n",
        "#     def test(self):\n",
        "#           out = model(self.data)\n",
        "#           test_loss = self.criterion(out[self.data.test_mask], self.data.y[self.data.test_mask])\n",
        "#           pred = out.argmax(dim=1)\n",
        "#           test_correct = pred[self.data.test_mask] == self.data.y[self.data.test_mask]\n",
        "#           test_acc = int(test_correct.sum()) / int(self.data.test_mask.sum())\n",
        "#           return test_acc, test_loss\n",
        "    \n",
        "#     def fit_optimize(self, epochs):\n",
        "#       for epoch in range(1, epochs+1):\n",
        "#         train_loss, validation_loss, save_model_flag = self.training()\n",
        "#         print(f'Epoch: {epoch:03d}, Trian Loss: {train_loss:.4f}, Validation Loss: {validation_loss:.4f}')\n",
        "#         if save_model_flag:\n",
        "#           self.min_valid_loss = validation_loss\n",
        "#           print(f\"Best validation loss: {self.min_valid_loss:.4f}\")\n",
        "#           print(f\"Saving best model for epoch: {epoch}\")\n",
        "#           torch.save(model,'best_model.pth')\n"
      ],
      "metadata": {
        "id": "duu9oGRBsZdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_channel=256,\n",
        "        learning_rate=0.01\n",
        "        \n",
        "        ):\n",
        "      \n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channel)\n",
        "        self.conv2 = GCNConv(hidden_channel, hidden_channel)\n",
        "        self.conv3 = GCNConv(hidden_channel, dataset.num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.tanh(x)\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "wN4RxnSyE7ax"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GCN(hidden_channel = 16)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjNrSNoWtumz",
        "outputId": "cdf576f4-8810-424f-f82d-88d919cf8e31"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN(\n",
            "  (conv1): GCNConv(1433, 16)\n",
            "  (conv2): GCNConv(16, 16)\n",
            "  (conv3): GCNConv(16, 7)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "learning_rate = 0.01\n",
        "min_valid_loss = np.inf\n",
        "epochs=150"
      ],
      "metadata": {
        "id": "EJiwlzeOs1Wv"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "data = dataset[0].to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "WZBaIFsHsuxB"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(min_valid_loss):\n",
        "      save_model_flag = False\n",
        "      model.train()\n",
        "      optimizer.zero_grad()\n",
        "      out = model(data)\n",
        "      train_loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "      validation_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
        "      if min_valid_loss > validation_loss:\n",
        "          save_model_flag = True\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      return train_loss, validation_loss, save_model_flag \n",
        "\n",
        "def test():\n",
        "      model.eval()\n",
        "      out = model(data)\n",
        "      test_loss = criterion(out[data.test_mask], data.y[data.test_mask])\n",
        "      pred = out.argmax(dim=1)\n",
        "      test_correct = pred[data.test_mask] == data.y[data.test_mask]\n",
        "      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())\n",
        "      return test_acc, test_loss"
      ],
      "metadata": {
        "id": "2l3geyW6r5Fj"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Performance"
      ],
      "metadata": {
        "id": "riqdhm_VgQ3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, epochs+1):\n",
        "  train_loss, validation_loss, save_model_flag = train(min_valid_loss)\n",
        "  print(f'Epoch: {epoch:03d}, Trian Loss: {train_loss:.4f}, Validation Loss: {validation_loss:.4f}')\n",
        "  if save_model_flag:\n",
        "    min_valid_loss = validation_loss\n",
        "    print()\n",
        "    print(f\"Best validation loss: {min_valid_loss:.4f}\")\n",
        "    print(f\"Saving best model for epoch: {epoch}\")\n",
        "    print()\n",
        "    torch.save(model,'best_model.pth')"
      ],
      "metadata": {
        "id": "9_Ze94DLMSaV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7a2e9ae-eaef-4258-ddd6-0aaec0f89b2f"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Trian Loss: 2.7715, Validation Loss: 2.7719\n",
            "\n",
            "Best validation loss: 2.7719\n",
            "Saving best model for epoch: 1\n",
            "\n",
            "Epoch: 002, Trian Loss: 2.7437, Validation Loss: 2.7486\n",
            "\n",
            "Best validation loss: 2.7486\n",
            "Saving best model for epoch: 2\n",
            "\n",
            "Epoch: 003, Trian Loss: 2.7120, Validation Loss: 2.7243\n",
            "\n",
            "Best validation loss: 2.7243\n",
            "Saving best model for epoch: 3\n",
            "\n",
            "Epoch: 004, Trian Loss: 2.6773, Validation Loss: 2.6960\n",
            "\n",
            "Best validation loss: 2.6960\n",
            "Saving best model for epoch: 4\n",
            "\n",
            "Epoch: 005, Trian Loss: 2.6335, Validation Loss: 2.6637\n",
            "\n",
            "Best validation loss: 2.6637\n",
            "Saving best model for epoch: 5\n",
            "\n",
            "Epoch: 006, Trian Loss: 2.5911, Validation Loss: 2.6245\n",
            "\n",
            "Best validation loss: 2.6245\n",
            "Saving best model for epoch: 6\n",
            "\n",
            "Epoch: 007, Trian Loss: 2.5456, Validation Loss: 2.5903\n",
            "\n",
            "Best validation loss: 2.5903\n",
            "Saving best model for epoch: 7\n",
            "\n",
            "Epoch: 008, Trian Loss: 2.4934, Validation Loss: 2.5478\n",
            "\n",
            "Best validation loss: 2.5478\n",
            "Saving best model for epoch: 8\n",
            "\n",
            "Epoch: 009, Trian Loss: 2.4419, Validation Loss: 2.5051\n",
            "\n",
            "Best validation loss: 2.5051\n",
            "Saving best model for epoch: 9\n",
            "\n",
            "Epoch: 010, Trian Loss: 2.3858, Validation Loss: 2.4658\n",
            "\n",
            "Best validation loss: 2.4658\n",
            "Saving best model for epoch: 10\n",
            "\n",
            "Epoch: 011, Trian Loss: 2.3281, Validation Loss: 2.4242\n",
            "\n",
            "Best validation loss: 2.4242\n",
            "Saving best model for epoch: 11\n",
            "\n",
            "Epoch: 012, Trian Loss: 2.2719, Validation Loss: 2.3814\n",
            "\n",
            "Best validation loss: 2.3814\n",
            "Saving best model for epoch: 12\n",
            "\n",
            "Epoch: 013, Trian Loss: 2.2202, Validation Loss: 2.3425\n",
            "\n",
            "Best validation loss: 2.3425\n",
            "Saving best model for epoch: 13\n",
            "\n",
            "Epoch: 014, Trian Loss: 2.1820, Validation Loss: 2.3116\n",
            "\n",
            "Best validation loss: 2.3116\n",
            "Saving best model for epoch: 14\n",
            "\n",
            "Epoch: 015, Trian Loss: 2.1219, Validation Loss: 2.2741\n",
            "\n",
            "Best validation loss: 2.2741\n",
            "Saving best model for epoch: 15\n",
            "\n",
            "Epoch: 016, Trian Loss: 2.1060, Validation Loss: 2.2487\n",
            "\n",
            "Best validation loss: 2.2487\n",
            "Saving best model for epoch: 16\n",
            "\n",
            "Epoch: 017, Trian Loss: 2.0480, Validation Loss: 2.2204\n",
            "\n",
            "Best validation loss: 2.2204\n",
            "Saving best model for epoch: 17\n",
            "\n",
            "Epoch: 018, Trian Loss: 2.0411, Validation Loss: 2.1846\n",
            "\n",
            "Best validation loss: 2.1846\n",
            "Saving best model for epoch: 18\n",
            "\n",
            "Epoch: 019, Trian Loss: 1.9937, Validation Loss: 2.1528\n",
            "\n",
            "Best validation loss: 2.1528\n",
            "Saving best model for epoch: 19\n",
            "\n",
            "Epoch: 020, Trian Loss: 1.9559, Validation Loss: 2.1061\n",
            "\n",
            "Best validation loss: 2.1061\n",
            "Saving best model for epoch: 20\n",
            "\n",
            "Epoch: 021, Trian Loss: 1.9339, Validation Loss: 2.0840\n",
            "\n",
            "Best validation loss: 2.0840\n",
            "Saving best model for epoch: 21\n",
            "\n",
            "Epoch: 022, Trian Loss: 1.8838, Validation Loss: 2.0361\n",
            "\n",
            "Best validation loss: 2.0361\n",
            "Saving best model for epoch: 22\n",
            "\n",
            "Epoch: 023, Trian Loss: 1.8604, Validation Loss: 1.9906\n",
            "\n",
            "Best validation loss: 1.9906\n",
            "Saving best model for epoch: 23\n",
            "\n",
            "Epoch: 024, Trian Loss: 1.8396, Validation Loss: 1.9487\n",
            "\n",
            "Best validation loss: 1.9487\n",
            "Saving best model for epoch: 24\n",
            "\n",
            "Epoch: 025, Trian Loss: 1.8021, Validation Loss: 1.9075\n",
            "\n",
            "Best validation loss: 1.9075\n",
            "Saving best model for epoch: 25\n",
            "\n",
            "Epoch: 026, Trian Loss: 1.7883, Validation Loss: 1.8771\n",
            "\n",
            "Best validation loss: 1.8771\n",
            "Saving best model for epoch: 26\n",
            "\n",
            "Epoch: 027, Trian Loss: 1.7619, Validation Loss: 1.8709\n",
            "\n",
            "Best validation loss: 1.8709\n",
            "Saving best model for epoch: 27\n",
            "\n",
            "Epoch: 028, Trian Loss: 1.7483, Validation Loss: 1.8339\n",
            "\n",
            "Best validation loss: 1.8339\n",
            "Saving best model for epoch: 28\n",
            "\n",
            "Epoch: 029, Trian Loss: 1.7306, Validation Loss: 1.8195\n",
            "\n",
            "Best validation loss: 1.8195\n",
            "Saving best model for epoch: 29\n",
            "\n",
            "Epoch: 030, Trian Loss: 1.7142, Validation Loss: 1.8069\n",
            "\n",
            "Best validation loss: 1.8069\n",
            "Saving best model for epoch: 30\n",
            "\n",
            "Epoch: 031, Trian Loss: 1.6545, Validation Loss: 1.7782\n",
            "\n",
            "Best validation loss: 1.7782\n",
            "Saving best model for epoch: 31\n",
            "\n",
            "Epoch: 032, Trian Loss: 1.6618, Validation Loss: 1.8016\n",
            "Epoch: 033, Trian Loss: 1.6474, Validation Loss: 1.7867\n",
            "Epoch: 034, Trian Loss: 1.5780, Validation Loss: 1.7812\n",
            "Epoch: 035, Trian Loss: 1.5728, Validation Loss: 1.7762\n",
            "\n",
            "Best validation loss: 1.7762\n",
            "Saving best model for epoch: 35\n",
            "\n",
            "Epoch: 036, Trian Loss: 1.5243, Validation Loss: 1.7672\n",
            "\n",
            "Best validation loss: 1.7672\n",
            "Saving best model for epoch: 36\n",
            "\n",
            "Epoch: 037, Trian Loss: 1.5016, Validation Loss: 1.7476\n",
            "\n",
            "Best validation loss: 1.7476\n",
            "Saving best model for epoch: 37\n",
            "\n",
            "Epoch: 038, Trian Loss: 1.4730, Validation Loss: 1.7593\n",
            "Epoch: 039, Trian Loss: 1.4571, Validation Loss: 1.7117\n",
            "\n",
            "Best validation loss: 1.7117\n",
            "Saving best model for epoch: 39\n",
            "\n",
            "Epoch: 040, Trian Loss: 1.4260, Validation Loss: 1.6890\n",
            "\n",
            "Best validation loss: 1.6890\n",
            "Saving best model for epoch: 40\n",
            "\n",
            "Epoch: 041, Trian Loss: 1.3543, Validation Loss: 1.6593\n",
            "\n",
            "Best validation loss: 1.6593\n",
            "Saving best model for epoch: 41\n",
            "\n",
            "Epoch: 042, Trian Loss: 1.3052, Validation Loss: 1.6107\n",
            "\n",
            "Best validation loss: 1.6107\n",
            "Saving best model for epoch: 42\n",
            "\n",
            "Epoch: 043, Trian Loss: 1.3075, Validation Loss: 1.6017\n",
            "\n",
            "Best validation loss: 1.6017\n",
            "Saving best model for epoch: 43\n",
            "\n",
            "Epoch: 044, Trian Loss: 1.2746, Validation Loss: 1.5368\n",
            "\n",
            "Best validation loss: 1.5368\n",
            "Saving best model for epoch: 44\n",
            "\n",
            "Epoch: 045, Trian Loss: 1.2547, Validation Loss: 1.5431\n",
            "Epoch: 046, Trian Loss: 1.1941, Validation Loss: 1.5209\n",
            "\n",
            "Best validation loss: 1.5209\n",
            "Saving best model for epoch: 46\n",
            "\n",
            "Epoch: 047, Trian Loss: 1.1675, Validation Loss: 1.4901\n",
            "\n",
            "Best validation loss: 1.4901\n",
            "Saving best model for epoch: 47\n",
            "\n",
            "Epoch: 048, Trian Loss: 1.1002, Validation Loss: 1.4459\n",
            "\n",
            "Best validation loss: 1.4459\n",
            "Saving best model for epoch: 48\n",
            "\n",
            "Epoch: 049, Trian Loss: 1.0760, Validation Loss: 1.4263\n",
            "\n",
            "Best validation loss: 1.4263\n",
            "Saving best model for epoch: 49\n",
            "\n",
            "Epoch: 050, Trian Loss: 1.0210, Validation Loss: 1.4249\n",
            "\n",
            "Best validation loss: 1.4249\n",
            "Saving best model for epoch: 50\n",
            "\n",
            "Epoch: 051, Trian Loss: 0.9800, Validation Loss: 1.4120\n",
            "\n",
            "Best validation loss: 1.4120\n",
            "Saving best model for epoch: 51\n",
            "\n",
            "Epoch: 052, Trian Loss: 0.9394, Validation Loss: 1.3784\n",
            "\n",
            "Best validation loss: 1.3784\n",
            "Saving best model for epoch: 52\n",
            "\n",
            "Epoch: 053, Trian Loss: 0.9406, Validation Loss: 1.3658\n",
            "\n",
            "Best validation loss: 1.3658\n",
            "Saving best model for epoch: 53\n",
            "\n",
            "Epoch: 054, Trian Loss: 0.8938, Validation Loss: 1.3536\n",
            "\n",
            "Best validation loss: 1.3536\n",
            "Saving best model for epoch: 54\n",
            "\n",
            "Epoch: 055, Trian Loss: 0.8501, Validation Loss: 1.3132\n",
            "\n",
            "Best validation loss: 1.3132\n",
            "Saving best model for epoch: 55\n",
            "\n",
            "Epoch: 056, Trian Loss: 0.7851, Validation Loss: 1.2955\n",
            "\n",
            "Best validation loss: 1.2955\n",
            "Saving best model for epoch: 56\n",
            "\n",
            "Epoch: 057, Trian Loss: 0.7742, Validation Loss: 1.2648\n",
            "\n",
            "Best validation loss: 1.2648\n",
            "Saving best model for epoch: 57\n",
            "\n",
            "Epoch: 058, Trian Loss: 0.7538, Validation Loss: 1.2319\n",
            "\n",
            "Best validation loss: 1.2319\n",
            "Saving best model for epoch: 58\n",
            "\n",
            "Epoch: 059, Trian Loss: 0.7284, Validation Loss: 1.2161\n",
            "\n",
            "Best validation loss: 1.2161\n",
            "Saving best model for epoch: 59\n",
            "\n",
            "Epoch: 060, Trian Loss: 0.6695, Validation Loss: 1.1707\n",
            "\n",
            "Best validation loss: 1.1707\n",
            "Saving best model for epoch: 60\n",
            "\n",
            "Epoch: 061, Trian Loss: 0.6349, Validation Loss: 1.1421\n",
            "\n",
            "Best validation loss: 1.1421\n",
            "Saving best model for epoch: 61\n",
            "\n",
            "Epoch: 062, Trian Loss: 0.6306, Validation Loss: 1.1265\n",
            "\n",
            "Best validation loss: 1.1265\n",
            "Saving best model for epoch: 62\n",
            "\n",
            "Epoch: 063, Trian Loss: 0.6137, Validation Loss: 1.1234\n",
            "\n",
            "Best validation loss: 1.1234\n",
            "Saving best model for epoch: 63\n",
            "\n",
            "Epoch: 064, Trian Loss: 0.5921, Validation Loss: 1.1133\n",
            "\n",
            "Best validation loss: 1.1133\n",
            "Saving best model for epoch: 64\n",
            "\n",
            "Epoch: 065, Trian Loss: 0.5595, Validation Loss: 1.0753\n",
            "\n",
            "Best validation loss: 1.0753\n",
            "Saving best model for epoch: 65\n",
            "\n",
            "Epoch: 066, Trian Loss: 0.5285, Validation Loss: 1.0523\n",
            "\n",
            "Best validation loss: 1.0523\n",
            "Saving best model for epoch: 66\n",
            "\n",
            "Epoch: 067, Trian Loss: 0.4714, Validation Loss: 1.0334\n",
            "\n",
            "Best validation loss: 1.0334\n",
            "Saving best model for epoch: 67\n",
            "\n",
            "Epoch: 068, Trian Loss: 0.4607, Validation Loss: 1.0606\n",
            "Epoch: 069, Trian Loss: 0.4227, Validation Loss: 1.0429\n",
            "Epoch: 070, Trian Loss: 0.4335, Validation Loss: 1.0397\n",
            "Epoch: 071, Trian Loss: 0.3983, Validation Loss: 1.0337\n",
            "Epoch: 072, Trian Loss: 0.3845, Validation Loss: 1.0103\n",
            "\n",
            "Best validation loss: 1.0103\n",
            "Saving best model for epoch: 72\n",
            "\n",
            "Epoch: 073, Trian Loss: 0.3745, Validation Loss: 0.9858\n",
            "\n",
            "Best validation loss: 0.9858\n",
            "Saving best model for epoch: 73\n",
            "\n",
            "Epoch: 074, Trian Loss: 0.3393, Validation Loss: 0.9833\n",
            "\n",
            "Best validation loss: 0.9833\n",
            "Saving best model for epoch: 74\n",
            "\n",
            "Epoch: 075, Trian Loss: 0.3050, Validation Loss: 0.9471\n",
            "\n",
            "Best validation loss: 0.9471\n",
            "Saving best model for epoch: 75\n",
            "\n",
            "Epoch: 076, Trian Loss: 0.2949, Validation Loss: 0.9528\n",
            "Epoch: 077, Trian Loss: 0.2695, Validation Loss: 0.9385\n",
            "\n",
            "Best validation loss: 0.9385\n",
            "Saving best model for epoch: 77\n",
            "\n",
            "Epoch: 078, Trian Loss: 0.2688, Validation Loss: 0.9402\n",
            "Epoch: 079, Trian Loss: 0.2507, Validation Loss: 0.9160\n",
            "\n",
            "Best validation loss: 0.9160\n",
            "Saving best model for epoch: 79\n",
            "\n",
            "Epoch: 080, Trian Loss: 0.2503, Validation Loss: 0.9146\n",
            "\n",
            "Best validation loss: 0.9146\n",
            "Saving best model for epoch: 80\n",
            "\n",
            "Epoch: 081, Trian Loss: 0.2202, Validation Loss: 0.8783\n",
            "\n",
            "Best validation loss: 0.8783\n",
            "Saving best model for epoch: 81\n",
            "\n",
            "Epoch: 082, Trian Loss: 0.2141, Validation Loss: 0.9283\n",
            "Epoch: 083, Trian Loss: 0.2105, Validation Loss: 0.9476\n",
            "Epoch: 084, Trian Loss: 0.1758, Validation Loss: 0.9143\n",
            "Epoch: 085, Trian Loss: 0.1921, Validation Loss: 0.8946\n",
            "Epoch: 086, Trian Loss: 0.1719, Validation Loss: 0.9011\n",
            "Epoch: 087, Trian Loss: 0.1664, Validation Loss: 0.9310\n",
            "Epoch: 088, Trian Loss: 0.1582, Validation Loss: 0.9652\n",
            "Epoch: 089, Trian Loss: 0.1710, Validation Loss: 0.9340\n",
            "Epoch: 090, Trian Loss: 0.1328, Validation Loss: 0.9709\n",
            "Epoch: 091, Trian Loss: 0.1308, Validation Loss: 0.9326\n",
            "Epoch: 092, Trian Loss: 0.1314, Validation Loss: 0.9451\n",
            "Epoch: 093, Trian Loss: 0.1346, Validation Loss: 0.9498\n",
            "Epoch: 094, Trian Loss: 0.1146, Validation Loss: 0.9343\n",
            "Epoch: 095, Trian Loss: 0.1273, Validation Loss: 0.8877\n",
            "Epoch: 096, Trian Loss: 0.1117, Validation Loss: 0.9618\n",
            "Epoch: 097, Trian Loss: 0.0962, Validation Loss: 0.9057\n",
            "Epoch: 098, Trian Loss: 0.0927, Validation Loss: 0.9108\n",
            "Epoch: 099, Trian Loss: 0.1048, Validation Loss: 0.8391\n",
            "\n",
            "Best validation loss: 0.8391\n",
            "Saving best model for epoch: 99\n",
            "\n",
            "Epoch: 100, Trian Loss: 0.0862, Validation Loss: 0.9127\n",
            "Epoch: 101, Trian Loss: 0.0810, Validation Loss: 0.9157\n",
            "Epoch: 102, Trian Loss: 0.0676, Validation Loss: 0.8949\n",
            "Epoch: 103, Trian Loss: 0.0695, Validation Loss: 0.9443\n",
            "Epoch: 104, Trian Loss: 0.0885, Validation Loss: 0.8975\n",
            "Epoch: 105, Trian Loss: 0.0732, Validation Loss: 0.9356\n",
            "Epoch: 106, Trian Loss: 0.0750, Validation Loss: 0.9266\n",
            "Epoch: 107, Trian Loss: 0.0604, Validation Loss: 1.0054\n",
            "Epoch: 108, Trian Loss: 0.0636, Validation Loss: 0.9965\n",
            "Epoch: 109, Trian Loss: 0.0651, Validation Loss: 1.0094\n",
            "Epoch: 110, Trian Loss: 0.0555, Validation Loss: 0.9787\n",
            "Epoch: 111, Trian Loss: 0.0708, Validation Loss: 1.0225\n",
            "Epoch: 112, Trian Loss: 0.0492, Validation Loss: 0.9815\n",
            "Epoch: 113, Trian Loss: 0.0517, Validation Loss: 1.0181\n",
            "Epoch: 114, Trian Loss: 0.0462, Validation Loss: 0.9867\n",
            "Epoch: 115, Trian Loss: 0.0498, Validation Loss: 0.9847\n",
            "Epoch: 116, Trian Loss: 0.0481, Validation Loss: 0.9213\n",
            "Epoch: 117, Trian Loss: 0.0450, Validation Loss: 0.9650\n",
            "Epoch: 118, Trian Loss: 0.0440, Validation Loss: 0.9973\n",
            "Epoch: 119, Trian Loss: 0.0431, Validation Loss: 0.9097\n",
            "Epoch: 120, Trian Loss: 0.0483, Validation Loss: 0.9364\n",
            "Epoch: 121, Trian Loss: 0.0436, Validation Loss: 0.9688\n",
            "Epoch: 122, Trian Loss: 0.0396, Validation Loss: 0.9821\n",
            "Epoch: 123, Trian Loss: 0.0403, Validation Loss: 0.9287\n",
            "Epoch: 124, Trian Loss: 0.0384, Validation Loss: 0.9559\n",
            "Epoch: 125, Trian Loss: 0.0338, Validation Loss: 1.0080\n",
            "Epoch: 126, Trian Loss: 0.0386, Validation Loss: 0.9933\n",
            "Epoch: 127, Trian Loss: 0.0381, Validation Loss: 0.9300\n",
            "Epoch: 128, Trian Loss: 0.0361, Validation Loss: 0.9330\n",
            "Epoch: 129, Trian Loss: 0.0348, Validation Loss: 0.9576\n",
            "Epoch: 130, Trian Loss: 0.0348, Validation Loss: 0.9977\n",
            "Epoch: 131, Trian Loss: 0.0326, Validation Loss: 0.9985\n",
            "Epoch: 132, Trian Loss: 0.0268, Validation Loss: 0.9504\n",
            "Epoch: 133, Trian Loss: 0.0318, Validation Loss: 0.9446\n",
            "Epoch: 134, Trian Loss: 0.0307, Validation Loss: 1.0090\n",
            "Epoch: 135, Trian Loss: 0.0261, Validation Loss: 0.9846\n",
            "Epoch: 136, Trian Loss: 0.0230, Validation Loss: 1.0709\n",
            "Epoch: 137, Trian Loss: 0.0341, Validation Loss: 0.9964\n",
            "Epoch: 138, Trian Loss: 0.0301, Validation Loss: 1.0011\n",
            "Epoch: 139, Trian Loss: 0.0291, Validation Loss: 1.0456\n",
            "Epoch: 140, Trian Loss: 0.0236, Validation Loss: 1.0210\n",
            "Epoch: 141, Trian Loss: 0.0284, Validation Loss: 1.0309\n",
            "Epoch: 142, Trian Loss: 0.0213, Validation Loss: 1.0394\n",
            "Epoch: 143, Trian Loss: 0.0292, Validation Loss: 1.0453\n",
            "Epoch: 144, Trian Loss: 0.0262, Validation Loss: 1.0072\n",
            "Epoch: 145, Trian Loss: 0.0232, Validation Loss: 1.0803\n",
            "Epoch: 146, Trian Loss: 0.0248, Validation Loss: 0.9866\n",
            "Epoch: 147, Trian Loss: 0.0281, Validation Loss: 1.0739\n",
            "Epoch: 148, Trian Loss: 0.0227, Validation Loss: 0.9799\n",
            "Epoch: 149, Trian Loss: 0.0274, Validation Loss: 1.0660\n",
            "Epoch: 150, Trian Loss: 0.0166, Validation Loss: 0.9972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('best_model.pth')\n",
        "test_acc, test_loss = test()\n",
        "print(f'Test Accuracy: {test_acc:.4f}, Test loss: {test_loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekvDcJFWMvw9",
        "outputId": "5824c824-fafe-47f9-bc4d-a449730dee0e"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.7710, Test loss: 0.7501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EG4FqUiCgVuZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}