{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mojtabaSefidi/Machine-Learning-with-Graphs/blob/main/MLG_Final_Project_100k_simulator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip ml-100k.zip\n",
        "# !pip uninstall jupyter\n",
        "# !pip install jupyter"
      ],
      "metadata": {
        "id": "2AK7CPIHJ2lq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwlKn2JrXvYo"
      },
      "source": [
        "## Install Essential Packages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHfg4IsV_paR",
        "outputId": "ec16a49a-ff32-444c-8eff-58b8778e9a3b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eyylEyBAw67k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82b58f44-9147-4801-f2d2-7d07a2ebdecd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/565.0 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.0/565.0 KB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for torch_geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 KB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch_scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q torch_geometric\n",
        "!pip install -q torch-sparse==0.6.13\n",
        "!pip install -q torch_scatter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcOrS826X3wJ"
      },
      "source": [
        "## Install Essential Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OCSrkduHlCPt"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import networkx as nx\n",
        "import torch_geometric\n",
        "from torch_geometric.utils import to_networkx\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, GraphConv, SAGEConv, global_add_pool\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric import transforms\n",
        "from torch_geometric.loader import LinkNeighborLoader\n",
        "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import seed\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model"
      ],
      "metadata": {
        "id": "oWb4j2GQ0Mov"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from torch_geometric.loader import LinkNeighborLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import random\n",
        "import time"
      ],
      "metadata": {
        "id": "a8xk67dMCYId"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import seaborn as sn\n",
        "sn.set()\n",
        "\n",
        "def plot_confusion_matrix(confusion_matrix, title='', cmap ='Greens'):\n",
        "    df = pd.DataFrame(confusion_matrix, range(len(confusion_matrix)), range(len(confusion_matrix)))\n",
        "    plt.figure(figsize=(6,4))\n",
        "    if title == '' :\n",
        "        plt.title('Confusion Matrix')\n",
        "    else:\n",
        "        plt.title('Confusion Matrix for' + ' ' + title)\n",
        "    sn.set(font_scale=1)\n",
        "    sn.heatmap(df, annot=True, annot_kws={\"size\": 12},fmt='.0f',cmap=cmap) # font size\n",
        "    plt.ylabel('Actual label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()\n",
        "\n",
        "def save_evaluation_details(report, df, duration, title):\n",
        "  row = []\n",
        "  for item in list(report.values()):\n",
        "    if type(item) == dict:\n",
        "      row.extend(item.values())\n",
        "    else:\n",
        "      row.append(item)\n",
        "  \n",
        "  row.append(duration)\n",
        "  row.append(title)\n",
        "  return df.append(pd.DataFrame([row], columns=df.columns.values), ignore_index=True)"
      ],
      "metadata": {
        "id": "SqKQ3KDXDL7y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LswIWaVoX901"
      },
      "source": [
        "## Read the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "plfs4IO6DLFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def year_extractor(text):\n",
        "#   return text[text.rfind('(')+1:text.rfind(')')]\n",
        "\n",
        "def add_average_rating(rating_df, movies_df, Movie_id_col='MovieID', rating_col='Rating'):\n",
        "  \n",
        "  rating_avg = rating_df.groupby(Movie_id_col).mean()[rating_col].round(4).to_dict()\n",
        "  result = [] \n",
        "  for id in movies_df[Movie_id_col]:\n",
        "    result.append(rating_avg.get(id, 0))\n",
        "  movies_df['Average Rating'] = result\n",
        "  return movies_df\n",
        "\n",
        "# Occupation_mapper = { 0: \"other\", 1: \"academic/educator\", 2: \"artist\", 3: \"clerical/admin\",\n",
        "#                      4: \"college/grad student\",5: \"customer service\", 6: \"doctor/health care\",\n",
        "#                      7: \"executive/managerial\", 8: \"farmer\", 9: \"homemaker\", 10: \"K-12 student\",\n",
        "#                      11: \"lawyer\", 12: \"programmer\", 13: \"retired\", 14: \"sales/marketing\",\n",
        "#                      15: \"scientist\", 16: \"self-employed\", 17: \"technician/engineer\",\n",
        "#                      18: \"tradesman/craftsman\", 19: \"unemployed\", 20: \"writer\"}\n",
        "\n",
        "# def code2Occupation(occupation_col, mapper):\n",
        "#   return occupation_col.map(mapper)\n",
        "\n",
        "\n",
        "# def extract_user_feature(users_df):\n",
        "#   scaler = StandardScaler()\n",
        "#   age = scaler.fit_transform(users_df[['Age']])\n",
        "  \n",
        "#   encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "#   occupation = encoder.fit_transform(users_df[['Occupation']]).toarray()\n",
        "#   features = np.hstack((users_df[['Gender']], age, occupation))\n",
        "#   return torch.from_numpy(features).to(torch.float)\n",
        "\n",
        "# def extract_movie_feature(movies_df, mapper):\n",
        "#   scaler = StandardScaler()\n",
        "#   numerical = scaler.fit_transform(movies_df[['year',\t'averge_rating']])\n",
        "  \n",
        "#   categorical = geners2vector(movies_df['Genres'], mapper)\n",
        "#   features = np.hstack((numerical, categorical))\n",
        "#   return torch.from_numpy(features).to(torch.float)\n",
        "\n",
        "def Timestamp2Date(timestamp):\n",
        "  return datetime.utcfromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "def add_age_group(df, age_col='Age'):\n",
        "  bins= [0,20,25,39,60,110]\n",
        "  labels = ['Teenage','Young Adult','Adult', 'Older Adult','Old']\n",
        "  df['AgeGroup'] = pd.cut(df[age_col], bins=bins, labels=labels, right=False)\n",
        "  return df\n",
        "\n",
        "def find_unknowns(movies_df, title_col='Movie Title', movie_id_col='MovieID'):\n",
        "  unknown_movies = movies_df[movies_df[title_col]=='unknown'][movie_id_col]\n",
        "  return unknown_movies\n",
        "\n",
        "def remove_unknows(df, list_unknown_movies, movie_id_col='MovieID'):\n",
        "  return df[~df[movie_id_col].isin(list_unknown_movies)]\n"
      ],
      "metadata": {
        "id": "HBhT-AUneyoW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_AE(encoding_dim = 8, input_shape= 24):\n",
        "\n",
        "  input_dim = Input(shape = (input_shape, ))\n",
        "\n",
        "  encoded1 = Dense(16, activation = 'relu')(input_dim)\n",
        "  encoded2 = Dense(encoding_dim, activation = 'relu')(encoded1)\n",
        "\n",
        "  decoded1 = Dense(16, activation = 'relu')(encoded2)\n",
        "  decoded2 = Dense(input_shape, activation = 'relu')(decoded1)\n",
        "\n",
        "\n",
        "  autoencoder = Model(inputs = input_dim, outputs = decoded2)\n",
        "  encoder = Model(inputs = input_dim, outputs = encoded2)\n",
        "\n",
        "  autoencoder.compile(optimizer = keras.optimizers.Adadelta(learning_rate=0.05), loss = 'binary_crossentropy')\n",
        "  print(autoencoder.summary())\n",
        "  return autoencoder, encoder\n",
        "\n",
        "def train_reduce_AE(AE, encoder, features, epochs=50, batch_size=16):\n",
        "  print('---------------------------------------Trainig of AE Sarts...')\n",
        "  AE.fit(features, features, epochs=epochs, batch_size=batch_size, shuffle = True, verbose=0)\n",
        "  print('--------------------------------------- Dimensionality Reduction Sarts...')\n",
        "  return encoder.predict(features)"
      ],
      "metadata": {
        "id": "Qzop320ETt9q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PreProcess_Dfs():\n",
        "  def __init__(self,\n",
        "               movies_df_path,\n",
        "               users_df_path,\n",
        "               ratings_df_path,\n",
        "               train_df_path,\n",
        "               test_df_path,\n",
        "               ):\n",
        "    \n",
        "    self.movies_df = pd.read_csv(movies_df_path)\n",
        "    self.ratings_df_all = pd.read_csv(ratings_df_path)\n",
        "    self.users_df = pd.read_csv(users_df_path)\n",
        "    self.train_df_path = train_df_path\n",
        "    self.test_df_path = test_df_path\n",
        "    self.list_unknown_movies = find_unknowns(self.movies_df)\n",
        "  \n",
        "  def preprocess_movies_df(self):\n",
        "    self.movies_df = remove_unknows(self.movies_df, self.list_unknown_movies)\n",
        "    self.movies_df.drop(['video release date', 'IMDbURL'], axis=1, inplace=True)\n",
        "    self.movies_df['Release Date'] = pd.to_datetime(self.movies_df['Release Date'])\n",
        "    self.movies_df['Release Year'] = self.movies_df['Release Date'].dt.year\n",
        "    self.movies_df['Release Month'] = self.movies_df['Release Date'].dt.month\n",
        "    self.movies_df['Release Day'] = self.movies_df['Release Date'].dt.strftime('%j').apply(int)\n",
        "    self.movies_df = self.movies_df.sort_values(by=['Release Date']).reset_index(drop=True)\n",
        "    self.movies_df = add_average_rating(self.ratings_df_all, self.movies_df)\n",
        "\n",
        "  def preprocess_users_df(self):\n",
        "    self.users_df = add_age_group(self.users_df)\n",
        "\n",
        "  def preprocess_rating_df(self, ratings_df, extract_details=False):\n",
        "    ratings_df = remove_unknows(ratings_df, self.list_unknown_movies)\n",
        "    if extract_details:\n",
        "      ratings_df.loc[:,'Timestamp'] = ratings_df.loc[:,'Timestamp'].apply(Timestamp2Date)\n",
        "      ratings_df.sort_values(by='Timestamp', inplace=True)\n",
        "      ratings_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "      ratings_df.loc[:,'Timestamp'] = pd.to_datetime(ratings_df.loc[:,'Timestamp'])\n",
        "      ratings_df.loc[:,'Year'] = ratings_df.loc[:,'Timestamp'].dt.year\n",
        "      ratings_df.loc[:,'Month'] = ratings_df.loc[:,'Timestamp'].dt.month\n",
        "      ratings_df.loc[:,'Weekday'] = ratings_df.loc[:,'Timestamp'].dt.weekday\n",
        "      ratings_df.loc[:,'Hour'] = ratings_df.loc[:,'Timestamp'].dt.hour\n",
        "      ratings_df.loc[:,'DayofYear'] = ratings_df.loc[:,'Timestamp'].dt.strftime('%j')\n",
        "    \n",
        "    return ratings_df\n",
        "  \n",
        "  def generate_train_validation(self, factor=0.5):\n",
        "    df = pd.read_csv(self.train_df_path, sep='\\t', engine='python', encoding=\"latin-1\",\n",
        "                            names=['UserID','MovieID','Rating','Timestamp'])\n",
        "    train_df = pd.DataFrame(columns=['UserID','MovieID','Rating','Timestamp'])\n",
        "    validation_df = pd.DataFrame(columns=['UserID','MovieID','Rating','Timestamp'])\n",
        "    for movie_id in df['MovieID'].unique():\n",
        "      df_temp = df[df['MovieID']== movie_id]\n",
        "      df_temp = df_temp.sort_values('Timestamp')\n",
        "      lenght_window = len(df_temp)\n",
        "      if lenght_window != 1:\n",
        "        cut = round(lenght_window * factor)  \n",
        "        train_df = pd.concat([train_df, df_temp.iloc[:cut,:]])\n",
        "        validation_df = pd.concat([validation_df, df_temp.iloc[cut:,:]])\n",
        "      elif (lenght_window != 1 and factor == 0.5): \n",
        "        if len(train_df) > len(validation_df):\n",
        "          validation_df = pd.concat([validation_df, df_temp])\n",
        "        elif len(train_df) < len(validation_df):\n",
        "          train_df = pd.concat([train_df, df_temp])\n",
        "        else:\n",
        "          if random.random() >= (1-factor):\n",
        "            train_df = pd.concat([train_df, df_temp])\n",
        "          else:\n",
        "            validation_df = pd.concat([validation_df, df_temp])\n",
        "      else:\n",
        "          if random.random() >= (1-factor):\n",
        "            train_df = pd.concat([train_df, df_temp])\n",
        "          else:\n",
        "            validation_df = pd.concat([validation_df, df_temp])\n",
        "\n",
        "    train_df = self.preprocess_rating_df(train_df)\n",
        "    validation_df = self.preprocess_rating_df(validation_df)\n",
        "    return train_df.reset_index(drop=True), validation_df.reset_index(drop=True)\n",
        "\n",
        "  def generate_test(self):\n",
        "    test_df = pd.read_csv(self.test_df_path, sep='\\t', engine='python', encoding=\"latin-1\",\n",
        "                          names=['UserID','MovieID','Rating','Timestamp'])\n",
        "    test_df = self.preprocess_rating_df(test_df)\n",
        "    return test_df.reset_index(drop=True)\n",
        "\n",
        "  def finalize_dfs(self,\n",
        "                 train_rating_df, validation_rating_df, test_rating_df,\n",
        "                 user_id_col='UserID', movie_id_col='MovieID'\n",
        "                 ):\n",
        "  \n",
        "    unique_user_id = self.users_df['UserID'].unique()\n",
        "    unique_user_id = pd.DataFrame(data={\n",
        "        'UserID': unique_user_id,\n",
        "        'mappedID': pd.RangeIndex(len(unique_user_id))\n",
        "        })\n",
        "    userid_mapper = dict(zip(unique_user_id.iloc[:,0], unique_user_id.iloc[:,-1]))\n",
        "    \n",
        "    # print(\"1. Mapping UserID to consecutive values... \")\n",
        "\n",
        "    unique_movie_id = self.movies_df['MovieID'].unique()\n",
        "    unique_movie_id = pd.DataFrame(data={\n",
        "        'MovieID': unique_movie_id,\n",
        "        'mappedID': pd.RangeIndex(len(unique_movie_id))\n",
        "        })\n",
        "    movieid_mapper = dict(zip(unique_movie_id.iloc[:,0], unique_movie_id.iloc[:,-1]))\n",
        "    # print(\"2. Mapping MovieID to consecutive values... \")\n",
        "\n",
        "    self.users_df['UserID'] = self.users_df['UserID'].map(userid_mapper)\n",
        "    self.users_df = self.users_df.sort_values(by='UserID').reset_index(drop=True)\n",
        "    self.movies_df['MovieID'] =  self.movies_df['MovieID'].map(movieid_mapper)\n",
        "    self.movies_df = self.movies_df.sort_values(by='MovieID').reset_index(drop=True)\n",
        "    train_rating_df['UserID'] = train_rating_df['UserID'].map(userid_mapper)\n",
        "    train_rating_df['MovieID'] =  train_rating_df['MovieID'].map(movieid_mapper)\n",
        "    validation_rating_df['UserID'] = validation_rating_df['UserID'].map(userid_mapper)\n",
        "    validation_rating_df['MovieID'] =  validation_rating_df['MovieID'].map(movieid_mapper)\n",
        "    test_rating_df['UserID'] = test_rating_df['UserID'].map(userid_mapper)\n",
        "    test_rating_df['MovieID'] =  test_rating_df['MovieID'].map(movieid_mapper)\n",
        "\n",
        "    self.users_df = self.users_df.sort_values(by=user_id_col).reset_index(drop=True)\n",
        "    self.movies_df = self.movies_df.sort_values(by=movie_id_col).reset_index(drop=True)\n",
        "    train_rating_df = train_rating_df.sort_values(by=[user_id_col, movie_id_col]).reset_index(drop=True)\n",
        "    validation_rating_df = validation_rating_df.sort_values(by=[user_id_col, movie_id_col]).reset_index(drop=True)\n",
        "    test_rating_df = test_rating_df.sort_values(by=[user_id_col, movie_id_col]).reset_index(drop=True)\n",
        "    return train_rating_df, validation_rating_df, test_rating_df\n",
        "  \n",
        "  def extract_user_feature(self):\n",
        "    scaler = StandardScaler()\n",
        "    age = scaler.fit_transform(self.users_df[['Age']])\n",
        "    \n",
        "    encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "    categorical_df = encoder.fit_transform(self.users_df[['Occupation', 'Gender']]).toarray()\n",
        "    features = np.hstack((categorical_df, age))\n",
        "    return features\n",
        "\n",
        "  def extract_movie_feature(self, exclude_cols=['MovieID','Movie Title', 'Release Date']):\n",
        "    movies_df = self.movies_df.drop(exclude_cols, axis=1)\n",
        "    scaler = StandardScaler()\n",
        "    movies_df[['Release Year', 'Release Month', 'Average Rating', 'Release Day']] = scaler.fit_transform(\n",
        "        movies_df[['Release Year', 'Release Month', 'Average Rating', 'Release Day']])\n",
        "    features = movies_df.to_numpy()\n",
        "    return features\n",
        "  \n",
        "  def PCA_DR(self, features, component=16):\n",
        "    pca = PCA(component)\n",
        "    return pca.fit_transform(features)\n",
        "  \n",
        "  def AE_DR(self, features, encoding_dim=16):\n",
        "    AE, encoder = build_AE(encoding_dim = encoding_dim, input_shape= features.shape[-1])\n",
        "    return train_reduce_AE(AE, encoder, features)\n",
        "\n",
        "  def main(self, DR_Approach='PCA', split_factor=0.5):\n",
        "    print('1. PreProcessing of Movies and users data-frames...')\n",
        "    self.preprocess_movies_df()\n",
        "    self.preprocess_users_df()\n",
        "\n",
        "    print('2. Generate Train/ Validation/ Test data-frames...')\n",
        "    train_df, validation_df = self.generate_train_validation(factor=split_factor)\n",
        "    test_df = self.generate_test()\n",
        "    \n",
        "    print('3. PreProcessing of Train/ Validation/ Test data-frames...')\n",
        "    train_df = self.preprocess_rating_df(train_df)\n",
        "    validation_df = self.preprocess_rating_df(validation_df)\n",
        "    test_df = self.preprocess_rating_df(test_df)\n",
        "    \n",
        "    print('4. Finalizing all data-frames...')\n",
        "    train_df, validation_df, test_df = self.finalize_dfs(train_df, validation_df, test_df)\n",
        "    \n",
        "    print('5. Extract users & movies features...')\n",
        "    user_features = self.extract_user_feature()\n",
        "    movie_features = self.extract_movie_feature()\n",
        "\n",
        "    if DR_Approach == 'PCA':\n",
        "      print('6. Reduce dimensionality of features...')\n",
        "      user_features = self.PCA_DR(user_features)\n",
        "      movie_features = self.PCA_DR(movie_features)\n",
        "\n",
        "    elif DR_Approach == 'AE':\n",
        "      print('6. Reduce dimensionality of features...')\n",
        "      user_features = self.AE_DR(user_features)\n",
        "      movie_features = self.AE_DR(movie_features)\n",
        "\n",
        "    print('------------ Finished ------------')\n",
        "    return train_df, validation_df, test_df, user_features, movie_features"
      ],
      "metadata": {
        "id": "6GvODCvaWdEW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Build_graphs():\n",
        "  def __init__(self,\n",
        "               train_df,\n",
        "               validation_df,\n",
        "               test_df,\n",
        "               ):\n",
        "    \n",
        "    self.train_df = train_df\n",
        "    self.validation_df = validation_df\n",
        "    self.test_df = test_df\n",
        "  \n",
        "  def generate_edge(self, rating_df, rating_threshold=0):\n",
        "\n",
        "    graph_edges = [[],[]]\n",
        "    edge_weight = []\n",
        "\n",
        "    for userID, movieID, rating in rating_df[['UserID','MovieID','Rating']].itertuples(index=False):\n",
        "      if rating >= rating_threshold:\n",
        "        graph_edges[0].append(userID)\n",
        "        graph_edges[1].append(movieID)\n",
        "        edge_weight.append(rating)\n",
        "      \n",
        "      else:\n",
        "        continue\n",
        "    \n",
        "    return torch.tensor(graph_edges, dtype=torch.long), torch.tensor(edge_weight, dtype=torch.float)\n",
        "\n",
        "  def generate_hetero_dataset(self, data, movies_df, users_df, movie_feature, user_feature, edges, labels):\n",
        "    dataset = HeteroData()\n",
        "\n",
        "    dataset[\"user\"].node_id = torch.tensor(users_df['UserID'].unique().astype(int), dtype=torch.int)\n",
        "    dataset[\"movie\"].node_id = torch.tensor(movies_df['MovieID'].unique().astype(int), dtype=torch.int)\n",
        "    dataset[\"movie\"].x = torch.tensor(movie_feature, dtype=torch.float)\n",
        "    dataset[\"user\"].x = torch.tensor(user_feature, dtype=torch.float)\n",
        "    dataset[\"user\", \"rates\", \"movie\"].edge_index = edges\n",
        "    dataset[\"user\", \"rates\", \"movie\"].edge_label_index = edges\n",
        "    dataset[\"user\", \"rates\", \"movie\"].edge_label = labels\n",
        "\n",
        "    dataset = transforms.ToUndirected()(dataset)\n",
        "    dataset = transforms.NormalizeFeatures()(dataset)\n",
        "    return dataset\n",
        "  \n",
        "  def generate_data_loader(self, dataset):\n",
        "    edge_label_index = dataset[\"user\", \"rates\", \"movie\"].edge_label_index\n",
        "    edge_label = dataset[\"user\", \"rates\", \"movie\"].edge_label\n",
        "    data_loader = LinkNeighborLoader(\n",
        "        data=dataset,\n",
        "        num_neighbors=[20, 10],\n",
        "        neg_sampling_ratio=2.0,\n",
        "        edge_label_index=((\"user\", \"rates\", \"movie\"), edge_label_index),\n",
        "        edge_label=edge_label,\n",
        "        batch_size=32,\n",
        "        shuffle=True\n",
        "        )\n",
        "    return data_loader\n",
        "\n",
        "  def main(self, movies_df, users_df, user_features, movie_features):\n",
        "    \n",
        "    print('1. Extract graph edges and edges labels...')\n",
        "    graph_edges_train, label_train = self.generate_edge(self.train_df)\n",
        "    graph_edges_validation, label_validation = self.generate_edge(self.validation_df)\n",
        "    graph_edges_test, label_test = self.generate_edge(self.test_df)\n",
        "\n",
        "    print('2. Generate Train/ Validation/ Test datasets...')\n",
        "    train_dataset = self.generate_hetero_dataset(self.train_df, movies_df, users_df, movie_features, user_features, graph_edges_train, label_train)\n",
        "    validation_dataset = self.generate_hetero_dataset(self.validation_df, movies_df, users_df, movie_features, user_features, graph_edges_validation, label_validation)\n",
        "    test_dataset = self.generate_hetero_dataset(self.test_df, movies_df, users_df, movie_features, user_features, graph_edges_test, label_test)\n",
        "\n",
        "    \n",
        "    print('3. Convert Train/ Validation/ Test datasets to form of data-loders...')\n",
        "    train_loader = self.generate_data_loader(train_dataset)\n",
        "    validation_loader = self.generate_data_loader(validation_dataset)\n",
        "    test_loader = self.generate_data_loader(test_dataset)\n",
        "    \n",
        "    print('------------ Finished ------------')\n",
        "    return train_dataset, train_loader, validation_loader, test_loader\n"
      ],
      "metadata": {
        "id": "Lh9XVskreOFs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (validation_dataset[\"user\", \"rates\", \"movie\"].edge_index).max(), validation_dataset[\"movie\"].x.size(0)"
      ],
      "metadata": {
        "id": "bE3NUe5rGZ3Z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import SAGEConv, to_hetero\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.conv4 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.conv5 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.conv6 = SAGEConv(hidden_channels, hidden_channels)\n",
        "    \n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv4(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv5(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv6(x, edge_index)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class Classifier(torch.nn.Module):\n",
        "    def forward(self, x_user, x_movie, edge_label_index):\n",
        "\n",
        "        edge_feat_user = x_user[edge_label_index[0]]\n",
        "        edge_feat_movie = x_movie[edge_label_index[1]]\n",
        "\n",
        "        return (edge_feat_user * edge_feat_movie).sum(dim=-1)\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, data, hidden_channels, user_features_dim, movie_features_dim):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.user_lin = torch.nn.Linear(user_features_dim, hidden_channels)\n",
        "        self.movie_lin = torch.nn.Linear(movie_features_dim, hidden_channels)\n",
        "        self.user_emb = torch.nn.Embedding(data[\"user\"].num_nodes, hidden_channels)\n",
        "        self.movie_emb = torch.nn.Embedding(data[\"movie\"].num_nodes, hidden_channels)\n",
        "\n",
        "        self.gnn = GNN(hidden_channels)\n",
        "\n",
        "        self.gnn = to_hetero(self.gnn, metadata=data.metadata())\n",
        "        self.classifier = Classifier()\n",
        "    \n",
        "    def forward(self, data):\n",
        "        x_dict = {\n",
        "          \"user\": self.user_lin(data[\"user\"].x) + self.user_emb(data[\"user\"].node_id),\n",
        "          \"movie\": self.movie_lin(data[\"movie\"].x) + self.movie_emb(data[\"movie\"].node_id),\n",
        "        } \n",
        "\n",
        "        x_dict = self.gnn(x_dict, data.edge_index_dict)\n",
        "        pred = self.classifier(\n",
        "            x_dict[\"user\"],\n",
        "            x_dict[\"movie\"],\n",
        "            data[\"user\", \"rates\", \"movie\"].edge_label_index,\n",
        "        )\n",
        "        return pred\n",
        "        \n",
        "# model = Model(data=train_dataset , hidden_channels=64, user_features_dim=8, movie_features_dim=8)\n",
        "# model"
      ],
      "metadata": {
        "id": "ztVe6WBhHff0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# del user_autoencoder, user_encoder, movie_autoencoder, movie_encoder, pca"
      ],
      "metadata": {
        "id": "ibblIz44EMSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Learning_Evaluation(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        learning_rate=0.01,\n",
        "        best_results=[np.Inf, np.Inf, np.Inf, np.Inf, np.Inf],\n",
        "        ):\n",
        "      \n",
        "      super().__init__()\n",
        "      self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "      self.model = model.to(self.device)\n",
        "      self.optimizer = torch.optim.SGD(self.model.parameters(), lr=learning_rate)\n",
        "      self.criterion = torch.nn.MSELoss()\n",
        "      self.best_results = best_results\n",
        "    \n",
        "    def train(self, data_loader):\n",
        "        self.model.train()\n",
        "\n",
        "        for data in data_loader:\n",
        "            data.to(self.device)\n",
        "            out = self.model(data)\n",
        "            label = data[\"user\", \"rates\", \"movie\"].edge_label\n",
        "            loss = self.criterion(out, label)\n",
        "            # loss = F.mse_loss(pred, ground_truth)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "\n",
        "    def train_model(self, train_data_loader, validation_data_loader, n_epochs=15, best_model_saving_path='best_model.pth'):\n",
        "      \n",
        "      list_train_mse, list_train_rmse, list_validation_rmse, list_validation_mse = [], [], [], []\n",
        "      print('Train and Evaluation started...')\n",
        "      for epoch in range(1, n_epochs+1):\n",
        "          self.train(train_data_loader)\n",
        "          \n",
        "          _ , _ , train_rmse_loss, train_mse_loss = self.evaluate(train_data_loader)\n",
        "          list_train_mse.append(train_mse_loss)\n",
        "          list_train_rmse.append(train_rmse_loss)\n",
        "          \n",
        "          _ , _ , validation_rmse_loss, validation_mse_loss = self.evaluate(validation_data_loader)\n",
        "          list_validation_mse.append(validation_mse_loss)\n",
        "          list_validation_rmse.append(validation_rmse_loss)\n",
        "          \n",
        "          if self.best_results[-2] > validation_mse_loss :\n",
        "            self.best_results[0] = epoch\n",
        "            self.best_results[1], self.best_results[2] = train_mse_loss, train_rmse_loss\n",
        "            self.best_results[-2], self.best_results[-1] = validation_mse_loss, validation_rmse_loss\n",
        "            torch.save(self.model, best_model_saving_path)\n",
        "\n",
        "\n",
        "          print(f'Epoch: {epoch:03d}, Train MSE: {train_mse_loss:.4f}, Train RMSE: {train_rmse_loss:.4f}, Validation MSE: {validation_mse_loss:.4f}, Validation RMSE: {validation_rmse_loss:.4f}')\n",
        "      \n",
        "      print('---------------------------------------------------')\n",
        "      print('Train and Evaluation finished...')\n",
        "      print(f'Best Results of the model : Epoch: {self.best_results[0]:03d}, Train RMSE: {self.best_results[2]:.4f}, Validation RMSE: {self.best_results[-1]:.4f}')\n",
        "      print(f'Model weights restored from epoch: {self.best_results[0]:03d}')\n",
        "      return list_train_mse, list_train_rmse, list_validation_rmse, list_validation_mse\n",
        "\n",
        "    def evaluate(self, data_loder, best_model_path=None):\n",
        "      self.model.eval()\n",
        "      \n",
        "      if not best_model_path is None:\n",
        "        model = torch.load(best_model_path)\n",
        "      else:\n",
        "        model = self.model\n",
        "      predicted = []\n",
        "      labels = []\n",
        "      for data in data_loder:\n",
        "          with torch.no_grad():\n",
        "              data.to(self.device)\n",
        "              predicted.append(model(data))\n",
        "              labels.append(data[\"user\", \"rates\", \"movie\"].edge_label)\n",
        "\n",
        "      predicted = torch.cat(predicted, dim=0).cpu().numpy()\n",
        "      labels = torch.cat(labels, dim=0).cpu().numpy()\n",
        "      rmse = mean_squared_error(labels, predicted, squared=False)\n",
        "      mse = mean_squared_error(labels, predicted, squared=True)\n",
        "\n",
        "      return labels, predicted, rmse, mse\n",
        "\n",
        "      \n",
        "      "
      ],
      "metadata": {
        "id": "-S_c-jAzaYug"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_movies_df(movies_df, ratings_df_all):\n",
        "  movies_df.drop(['video release date', 'IMDbURL'], axis=1, inplace=True)\n",
        "  movies_df['Release Date'] = pd.to_datetime(movies_df['Release Date'])\n",
        "  movies_df['Release Year'] = movies_df['Release Date'].dt.year\n",
        "  movies_df['Release Month'] = movies_df['Release Date'].dt.month\n",
        "  movies_df['Release Day'] = movies_df['Release Date'].dt.strftime('%j').apply(int)\n",
        "  movies_df = movies_df.sort_values(by=['Release Date']).reset_index(drop=True)\n",
        "  movies_df = add_average_rating(ratings_df_all, movies_df)\n",
        "  return movies_df\n",
        "\n",
        "def finalize_dfs(\n",
        "    users_df, \n",
        "    movies_df,\n",
        "    user_id_col='UserID', movie_id_col='MovieID'\n",
        "                ):\n",
        "\n",
        "  unique_user_id = users_df[user_id_col].unique()\n",
        "  unique_user_id = pd.DataFrame(data={\n",
        "      user_id_col: unique_user_id,\n",
        "      'mappedID': pd.RangeIndex(len(unique_user_id))\n",
        "      })\n",
        "  userid_mapper = dict(zip(unique_user_id.iloc[:,0], unique_user_id.iloc[:,-1]))\n",
        "  \n",
        "  # print(\"1. Mapping UserID to consecutive values... \")\n",
        "\n",
        "  unique_movie_id = movies_df[movie_id_col].unique()\n",
        "  unique_movie_id = pd.DataFrame(data={\n",
        "      movie_id_col: unique_movie_id,\n",
        "      'mappedID': pd.RangeIndex(len(unique_movie_id))\n",
        "      })\n",
        "  movieid_mapper = dict(zip(unique_movie_id.iloc[:,0], unique_movie_id.iloc[:,-1]))\n",
        "  # print(\"2. Mapping MovieID to consecutive values... \")\n",
        "\n",
        "  users_df[user_id_col] = users_df[user_id_col].map(userid_mapper)\n",
        "  users_df = users_df.sort_values(by=user_id_col).reset_index(drop=True)\n",
        "  movies_df[movie_id_col] =  movies_df[movie_id_col].map(movieid_mapper)\n",
        "  movies_df = movies_df.sort_values(by=movie_id_col).reset_index(drop=True)\n",
        "\n",
        "  # return movies_df\n",
        "  return users_df, movies_df\n",
        "\n",
        "def extract_user_feature(users_df):\n",
        "  scaler = StandardScaler()\n",
        "  age = scaler.fit_transform(users_df[['Age']])\n",
        "  \n",
        "  encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "  categorical_df = encoder.fit_transform(users_df[['Occupation', 'Gender']]).toarray()\n",
        "  features = np.hstack((categorical_df, age))\n",
        "  return features\n",
        "\n",
        "def extract_movie_feature(movies_df, exclude_cols=['MovieID','Movie Title', 'Release Date']):\n",
        "  movies_df = movies_df.drop(exclude_cols, axis=1)\n",
        "  scaler = StandardScaler()\n",
        "  movies_df[['Release Year', 'Release Month', 'Average Rating', 'Release Day']] = scaler.fit_transform(\n",
        "      movies_df[['Release Year', 'Release Month', 'Average Rating', 'Release Day']])\n",
        "  features = movies_df.to_numpy()\n",
        "  return features"
      ],
      "metadata": {
        "id": "jKC_hKG5oku1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend(df_new_user, favorite_genres,\n",
        "              movies_df_path, users_df_path,\n",
        "              ratings_df_all_path, model_path,\n",
        "              k=5\n",
        "              ):\n",
        "  \n",
        "  movies_df = pd.read_csv(movies_df_path)\n",
        "  list_unknown_movies = find_unknowns(movies_df)\n",
        "  movies_df = remove_unknows(movies_df, list_unknown_movies)\n",
        "  users_df = pd.read_csv(users_df_path)\n",
        "  ratings_df_all = pd.read_csv(ratings_df_all_path)\n",
        "  movies_df = preprocess_movies_df(movies_df, ratings_df_all)\n",
        "\n",
        "  recommender_model = torch.load(model_path)\n",
        "  users_df.iloc[-len(df_new_user):, :] = df_new_user \n",
        "  # print(users_df.iloc[-len(df_new_user):, :])\n",
        "  # users_df = pd.concat([users_df, df_new_user], axis=0, ignore_index=True)\n",
        "  \n",
        "  users_df, movies_df = finalize_dfs(users_df, movies_df)\n",
        "  # movies_df = finalize_dfs(movies_df)\n",
        "  user_feature = extract_user_feature(users_df)\n",
        "  movie_feature = extract_movie_feature(movies_df)\n",
        "  \n",
        "  graph_edges = [[],[]]\n",
        "  edge_weight = []\n",
        "  \n",
        "  if favorite_genres != 'all':\n",
        "    temp_df = movies_df[movies_df[favorite_genres].apply(lambda r: (r==1).any(), axis=1)] \n",
        "  else:\n",
        "    temp_df = movies_df\n",
        "\n",
        "  for user_id in users_df.iloc[-len(df_new_user):, :]['UserID'].unique():\n",
        "    for movie_id in temp_df['MovieID'].unique():\n",
        "      graph_edges[0].append(user_id)\n",
        "      graph_edges[1].append(movie_id)\n",
        "      edge_weight.append(3)\n",
        "  \n",
        "  graph_edges, edge_weight = torch.tensor(graph_edges, dtype=torch.long), torch.tensor(edge_weight, dtype=torch.float)\n",
        "  \n",
        "  dataset = HeteroData()\n",
        "  \n",
        "  dataset[\"user\"].node_id = torch.tensor(users_df['UserID'].unique().astype(int), dtype=torch.int)\n",
        "  dataset[\"movie\"].node_id = torch.tensor(movies_df['MovieID'].unique().astype(int), dtype=torch.int)\n",
        "  dataset[\"movie\"].x = torch.tensor(movie_feature, dtype=torch.float)\n",
        "  dataset[\"user\"].x = torch.tensor(user_feature, dtype=torch.float)\n",
        "  dataset[\"user\", \"rates\", \"movie\"].edge_index = graph_edges\n",
        "  dataset[\"user\", \"rates\", \"movie\"].edge_label_index = graph_edges\n",
        "  dataset[\"user\", \"rates\", \"movie\"].edge_label = edge_weight\n",
        "  dataset = transforms.ToUndirected()(dataset)\n",
        "  dataset = transforms.NormalizeFeatures()(dataset)\n",
        "\n",
        "  edge_label_index = dataset[\"user\", \"rates\", \"movie\"].edge_label_index\n",
        "  edge_label = dataset[\"user\", \"rates\", \"movie\"].edge_label\n",
        "  data_loader = LinkNeighborLoader(\n",
        "      data=dataset,\n",
        "      num_neighbors=[20, 10],\n",
        "      neg_sampling_ratio=2.0,\n",
        "      edge_label_index=((\"user\", \"rates\", \"movie\"), edge_label_index),\n",
        "      edge_label=edge_label,\n",
        "      batch_size=32,\n",
        "      shuffle=True\n",
        "      )\n",
        "  \n",
        "  predictor = Learning_Evaluation(recommender_model)\n",
        "  _, predicted, _, _ = predictor.evaluate(data_loader)\n",
        "  \n",
        "  cut = len(predicted) // len(edge_weight)\n",
        "  preds = predicted.reshape(cut,-1).mean(axis=0)\n",
        "  top_edges_rates = preds.argsort()[-k:][::-1]\n",
        "  # print(preds,top_edges_rates, graph_edges[-1])\n",
        "  recommended_film = graph_edges[-1][list(top_edges_rates)]\n",
        "  return preds, movies_df, movies_df.iloc[recommended_film,:].T"
      ],
      "metadata": {
        "id": "IdgoQ6L3oksF"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "----------------Ocuppation\n",
        "administrator\n",
        "artist\n",
        "doctor\n",
        "educator\n",
        "engineer\n",
        "entertainment\n",
        "executive\n",
        "healthcare\n",
        "homemaker\n",
        "lawyer\n",
        "librarian\n",
        "marketing\n",
        "none\n",
        "other\n",
        "programmer\n",
        "retired\n",
        "salesman\n",
        "scientist\n",
        "student\n",
        "technician\n",
        "writer\n",
        "\n",
        "---------- Genre\n",
        "unknown|0\n",
        "Action|1\n",
        "Adventure|2\n",
        "Animation|3\n",
        "Children's|4\n",
        "Comedy|5\n",
        "Crime|6\n",
        "Documentary|7\n",
        "Drama|8\n",
        "Fantasy|9\n",
        "Film-Noir|10\n",
        "Horror|11\n",
        "Musical|12\n",
        "Mystery|13\n",
        "Romance|14\n",
        "Sci-Fi|15\n",
        "Thriller|16\n",
        "War|17\n",
        "Western|18\n",
        "'''\n",
        "\n",
        "# users_df = pd.read_csv('/content/gdrive/MyDrive/MLG_Final_Project/MovieLens100k/Data/users_df.csv')\n",
        "# users_df\n",
        "\n",
        "new_users = [[944, 24, 'F', 'educator', 85711]]\n",
        "favorite_genres = [[\"Romance\"]]\n"
      ],
      "metadata": {
        "id": "imjyoLkmpXzY"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(new_users)):\n",
        "  df_new_user = pd.DataFrame([new_users[i]], columns=['UserID', 'Age', 'Gender', 'Occupation', 'Zipcode'])\n",
        "  favorite_genre = favorite_genres[i]\n",
        "  predicted, movies_df, recommended_film = recommend(df_new_user, favorite_genre,\n",
        "                                                   movies_df_path = '/content/gdrive/MyDrive/MLG_Final_Project/MovieLens100k/Data/movies_df.csv',\n",
        "                                                   users_df_path='/content/gdrive/MyDrive/MLG_Final_Project/MovieLens100k/Data/users_df.csv', \n",
        "                                                   ratings_df_all_path = '/content/gdrive/MyDrive/MLG_Final_Project/MovieLens100k/Data/rating_df.csv',\n",
        "                                                   model_path='/content/best_model_GraphSage64_1.pth')"
      ],
      "metadata": {
        "id": "qBkrmboJ_cto"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommended_film"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "id": "SBkuF9A9nszi",
        "outputId": "432440a5-abfd-44ea-f6af-d1ff46a5287d"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     720                    756  \\\n",
              "MovieID                              720                    756   \n",
              "Movie Title     Radioland Murders (1994)  Goofy Movie, A (1995)   \n",
              "Release Date         1994-01-01 00:00:00    1995-01-01 00:00:00   \n",
              "Unknown                                0                      0   \n",
              "Action                                 0                      0   \n",
              "Adventure                              0                      0   \n",
              "Animation                              0                      1   \n",
              "Childrens                              0                      1   \n",
              "Comedy                                 1                      1   \n",
              "Crime                                  0                      0   \n",
              "Documentary                            0                      0   \n",
              "Drama                                  0                      0   \n",
              "Fantasy                                0                      0   \n",
              "Film-Noir                              0                      0   \n",
              "Horror                                 0                      0   \n",
              "Musical                                0                      0   \n",
              "Mystery                                1                      0   \n",
              "Romance                                1                      1   \n",
              "Sci-Fi                                 0                      0   \n",
              "Thriller                               0                      0   \n",
              "War                                    0                      0   \n",
              "Western                                0                      0   \n",
              "Release Year                        1994                   1995   \n",
              "Release Month                          1                      1   \n",
              "Release Day                            1                      1   \n",
              "Average Rating                    3.3333                    2.9   \n",
              "\n",
              "                                12                   683                  56   \n",
              "MovieID                          12                  683                   56  \n",
              "Movie Title          Top Hat (1935)         Speed (1994)    Spellbound (1945)  \n",
              "Release Date    1935-01-01 00:00:00  1994-01-01 00:00:00  1945-01-01 00:00:00  \n",
              "Unknown                           0                    0                    0  \n",
              "Action                            0                    1                    0  \n",
              "Adventure                         0                    0                    0  \n",
              "Animation                         0                    0                    0  \n",
              "Childrens                         0                    0                    0  \n",
              "Comedy                            1                    0                    0  \n",
              "Crime                             0                    0                    0  \n",
              "Documentary                       0                    0                    0  \n",
              "Drama                             0                    0                    0  \n",
              "Fantasy                           0                    0                    0  \n",
              "Film-Noir                         0                    0                    0  \n",
              "Horror                            0                    0                    0  \n",
              "Musical                           1                    0                    0  \n",
              "Mystery                           0                    0                    1  \n",
              "Romance                           1                    1                    1  \n",
              "Sci-Fi                            0                    0                    0  \n",
              "Thriller                          0                    1                    1  \n",
              "War                               0                    0                    0  \n",
              "Western                           0                    0                    0  \n",
              "Release Year                   1935                 1994                 1945  \n",
              "Release Month                     1                    1                    1  \n",
              "Release Day                       1                    1                    1  \n",
              "Average Rating               4.0476               3.6478               3.9333  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a6a7b49-a655-4810-a871-67ca013d8742\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>720</th>\n",
              "      <th>756</th>\n",
              "      <th>12</th>\n",
              "      <th>683</th>\n",
              "      <th>56</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MovieID</th>\n",
              "      <td>720</td>\n",
              "      <td>756</td>\n",
              "      <td>12</td>\n",
              "      <td>683</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Movie Title</th>\n",
              "      <td>Radioland Murders (1994)</td>\n",
              "      <td>Goofy Movie, A (1995)</td>\n",
              "      <td>Top Hat (1935)</td>\n",
              "      <td>Speed (1994)</td>\n",
              "      <td>Spellbound (1945)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Release Date</th>\n",
              "      <td>1994-01-01 00:00:00</td>\n",
              "      <td>1995-01-01 00:00:00</td>\n",
              "      <td>1935-01-01 00:00:00</td>\n",
              "      <td>1994-01-01 00:00:00</td>\n",
              "      <td>1945-01-01 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unknown</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Action</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adventure</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Animation</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Childrens</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Comedy</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Crime</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Documentary</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Drama</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fantasy</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Film-Noir</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Horror</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Musical</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mystery</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Romance</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sci-Fi</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Thriller</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>War</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Western</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Release Year</th>\n",
              "      <td>1994</td>\n",
              "      <td>1995</td>\n",
              "      <td>1935</td>\n",
              "      <td>1994</td>\n",
              "      <td>1945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Release Month</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Release Day</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Average Rating</th>\n",
              "      <td>3.3333</td>\n",
              "      <td>2.9</td>\n",
              "      <td>4.0476</td>\n",
              "      <td>3.6478</td>\n",
              "      <td>3.9333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a6a7b49-a655-4810-a871-67ca013d8742')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a6a7b49-a655-4810-a871-67ca013d8742 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a6a7b49-a655-4810-a871-67ca013d8742');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_hoNetWoAYuf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZJJWVlKNSsZ1Q1KaTi+dB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}