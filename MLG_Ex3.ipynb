{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mojtabaSefidi/Machine-Learning-with-Graphs/blob/main/MLG_Ex3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwlKn2JrXvYo"
      },
      "source": [
        "## Install Essential Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyylEyBAw67k",
        "outputId": "122dece0-84a4-4e43-d12f-9629cc694ec5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 564 kB 26.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 280 kB 73.3 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 48 kB 5.7 MB/s \n",
            "\u001b[?25h  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 106 kB 32.9 MB/s \n"
          ]
        }
      ],
      "source": [
        "!pip install -q torch_geometric\n",
        "!pip install -q torch-sparse==0.6.13\n",
        "!pip install -q torch_scatter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcOrS826X3wJ"
      },
      "source": [
        "## Install Essential Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCSrkduHlCPt"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "import torch\n",
        "import networkx as nx\n",
        "import torch_geometric\n",
        "from torch_geometric.utils import to_networkx\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, GraphConv, SAGEConv\n",
        "\n",
        "from torch_geometric.nn import global_mean_pool, global_max_pool, global_add_pool"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(list_train_loss, list_train_acc, list_val_loss, list_val_acc, n_epochs, title):\n",
        "    \n",
        "    plt.figure(figsize=(18,8),linewidth = 7, edgecolor=\"whitesmoke\")    \n",
        "    n = n_epochs\n",
        "    \n",
        "    plt.plot(list(range(1, n_epochs+1)), list_train_acc, color='orange',marker=\".\")\n",
        "    plt.plot(list(range(1, n_epochs+1)), list_train_loss,'b',marker=\".\")\n",
        "    \n",
        "    plt.plot(list(range(1, n_epochs+1)), list_val_acc,'r')  \n",
        "    plt.plot(list(range(1, n_epochs+1)), list_val_loss,'g')\n",
        "    \n",
        "    plt.legend(['Train Accuracy','Train Loss','Test Accuracy','Test Loss'])\n",
        "    plt.grid(True)\n",
        "    \n",
        "    # plt.gca().set_ylim(0,1)\n",
        "\n",
        "    plt.xlabel(\"Number of Epochs\")\n",
        "    plt.ylabel(\"Value\")\n",
        "    plt.suptitle(title, size=16, y=0.927)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "u58ez8Rrjjt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LswIWaVoX901"
      },
      "source": [
        "## Read the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjGUj-btw3_l"
      },
      "outputs": [],
      "source": [
        "dataset = TUDataset(root='/tmp/MUTAG', name='MUTAG', transform=NormalizeFeatures())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the Dataset"
      ],
      "metadata": {
        "id": "PsRdPLG1Xs-F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzS-UfyH8jrI"
      },
      "outputs": [],
      "source": [
        "def split_data(dataset, train_split_percentage):\n",
        "  cut_index = int(len(dataset) * train_split_percentage)\n",
        "  dataset = dataset.shuffle()\n",
        "  return dataset[:cut_index], dataset[cut_index:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset = split_data(dataset, train_split_percentage=0.8)\n",
        "print(f'Number of graphs in the Train Dataset: {len(train_dataset)}')\n",
        "print(f'Number of graphs in the Test Dataset: {len(test_dataset)}')"
      ],
      "metadata": {
        "id": "JZ32kg3MZDJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch Generator"
      ],
      "metadata": {
        "id": "653dTXpRXxGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_generator(train_dataset, test_dataset, batch_size, shuffle=True):\n",
        "  train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "  test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "  return train_data_loader, test_data_loader"
      ],
      "metadata": {
        "id": "mQDaOhdXXpg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sW8hRZar-3_X"
      },
      "outputs": [],
      "source": [
        "train_data_loader, test_data_loader =  batch_generator(train_dataset, test_dataset, batch_size=64)\n",
        "\n",
        "for batch, data in enumerate(train_data_loader):\n",
        "    print(f'Batch {batch + 1}:')\n",
        "    print('=======')\n",
        "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
        "    print(data)\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAcbp5Ji_yV1"
      },
      "outputs": [],
      "source": [
        "class GCN_Add_Pooling(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, hidden_channels, aggregation):\n",
        "        super(GCN_Add_Pooling, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        if type(aggregation) != list:\n",
        "          self.conv1 = GCNConv(dataset.num_node_features, hidden_channels, aggr=aggregation)\n",
        "          self.conv2 = GCNConv(hidden_channels, hidden_channels, aggr=aggregation)\n",
        "          self.conv3 = GCNConv(hidden_channels, hidden_channels, aggr=aggregation)\n",
        "          self.conv4 = GCNConv(hidden_channels, hidden_channels, aggr=aggregation)\n",
        "          self.lin = Linear(hidden_channels, dataset.num_classes)\n",
        "        else:\n",
        "          i=1\n",
        "          self.conv1 = GCNConv(dataset.num_node_features, hidden_channels*(len(aggregation)**(i)), aggr=aggregation, bias=False)\n",
        "          i+=1\n",
        "          self.conv2 = GCNConv(hidden_channels*(len(aggregation)**(i)), hidden_channels*(len(aggregation)**(i)), aggr=aggregation, bias=False)\n",
        "          i+=1\n",
        "          self.conv3 = GCNConv(hidden_channels*(len(aggregation)**(i)), hidden_channels*(len(aggregation)**(i)), aggr=aggregation, bias=False)\n",
        "          i+=1\n",
        "          self.conv4 = GCNConv(hidden_channels*(len(aggregation)**(i)), hidden_channels*(len(aggregation)**(i)), aggr=aggregation, bias=False)\n",
        "          self.lin = Linear(hidden_channels*(len(aggregation)**(i+1)), dataset.num_classes)\n",
        "        \n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv4(x, edge_index)\n",
        "\n",
        "        x = global_add_pool(x, batch)\n",
        "\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.lin(x)\n",
        "        \n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Graph_Sage(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(Graph_Sage, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.conv1 = SAGEConv(dataset.num_node_features, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.lin = Linear(hidden_channels, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        x = global_add_pool(x, batch)\n",
        "\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.lin(x)\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "a8i8obcdtZ-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Graph_Conv(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(Graph_Conv, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.conv1 = GraphConv(dataset.num_node_features, hidden_channels)\n",
        "        self.conv2 = GraphConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GraphConv(hidden_channels, hidden_channels)\n",
        "        self.lin = Linear(hidden_channels, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = x.relu()\n",
        "\n",
        "        x = global_add_pool(x, batch)\n",
        "\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.lin(x)\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "OubgXWNetZ8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Leaning_Evaluation(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        learning_rate=0.006,\n",
        "        best_results=[0, 0, 0],\n",
        "        ):\n",
        "      \n",
        "      super().__init__()\n",
        "      self.model = model\n",
        "      self.optimizer = torch.optim.Adam(self.model.parameters(), lr=learning_rate)\n",
        "      self.criterion = torch.nn.CrossEntropyLoss()\n",
        "      self.best_results = best_results\n",
        "    \n",
        "    def train(self, data_loader):\n",
        "        self.model.train()\n",
        "\n",
        "        for data in data_loader:\n",
        "            out = self.model(data.x, data.edge_index, data.batch)\n",
        "            loss = self.criterion(out, data.y)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "    def evaluate(self, data_loader):\n",
        "        self.model.eval()\n",
        "\n",
        "        correct, loss = 0, 0\n",
        "        for data in data_loader:\n",
        "            out = self.model(data.x, data.edge_index, data.batch)\n",
        "            loss += self.criterion(out, data.y)  \n",
        "            pred = out.argmax(dim=1)\n",
        "            correct += int((pred == data.y).sum())\n",
        "        return correct / len(data_loader.dataset), loss/ len(data_loader.dataset)\n",
        "\n",
        "    def train_and_evaluate(self, train_data_loader, test_data_loader, n_epochs=200):\n",
        "      \n",
        "      list_train_acc, list_train_loss, list_test_acc, list_test_loss = [], [], [], []\n",
        "      print('Train and Evaluation started...')\n",
        "      for epoch in range(1, n_epochs+1):\n",
        "          self.train(train_data_loader)\n",
        "          \n",
        "          train_accuracy, train_loss = self.evaluate(train_data_loader)\n",
        "          list_train_acc.append(train_accuracy)\n",
        "          list_train_loss.append(float(train_loss.detach()))\n",
        "          \n",
        "          test_accuracy, test_loss = self.evaluate(test_data_loader)\n",
        "          if self.best_results[-1] + self.best_results[1] < test_accuracy + train_accuracy :\n",
        "            self.best_results[0], self.best_results[1], self.best_results[-1] = epoch, train_accuracy ,test_accuracy\n",
        "\n",
        "          list_test_acc.append(test_accuracy)\n",
        "          list_test_loss.append(float(test_loss.detach()))\n",
        "\n",
        "          print(f'Epoch: {epoch:03d}, Train Accuracy: {train_accuracy:.4f}, Train Loss: {train_loss:.4f}, Test Accuracy: {test_accuracy:.4f}, Test Loss: {test_loss:.4f}')\n",
        "      \n",
        "      print('---------------------------------------------------')\n",
        "      print('Train and Evaluation finished...')\n",
        "      print(f'Best Results of the model : Epoch: {self.best_results[0]:03d}, Train Accuracy: {self.best_results[1]:.4f}, Test Accuracy: {self.best_results[-1]:.4f}')\n",
        "      return list_train_acc, list_train_loss, list_test_acc, list_test_loss\n",
        "      "
      ],
      "metadata": {
        "id": "V-kUmf2FywF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aggregation Function = add"
      ],
      "metadata": {
        "id": "QXQqMVPyW-nZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3XjuJw-AddD"
      },
      "outputs": [],
      "source": [
        "model = GCN_Add_Pooling(hidden_channels=64, aggregation='add')\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_GCN_Mean = Leaning_Evaluation(\n",
        "                                   model = model,\n",
        "                                   best_results=[0, 0, 0]\n",
        "                                   )\n",
        "list_train_acc, list_train_loss, list_test_acc, list_test_loss = evaluate_GCN_Mean.train_and_evaluate(train_data_loader, test_data_loader, n_epochs=100)"
      ],
      "metadata": {
        "id": "4ieP9LQQtdEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(list_train_loss, list_train_acc, list_test_loss, list_test_acc, n_epochs=100, title='GCN (Aggregation=add)')"
      ],
      "metadata": {
        "id": "E1LzfYC7vy6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aggregation Function = Max"
      ],
      "metadata": {
        "id": "vMstO9I0WbFq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ue1DvYzWWYMQ"
      },
      "outputs": [],
      "source": [
        "model = GCN_Add_Pooling(hidden_channels=64, aggregation='max')\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkjMJy3TWYMT"
      },
      "outputs": [],
      "source": [
        "evaluate_GCN_max = Leaning_Evaluation(\n",
        "                                   model = model,\n",
        "                                   best_results=[0, 0, 0]\n",
        "                                   )\n",
        "list_train_acc, list_train_loss, list_test_acc, list_test_loss = evaluate_GCN_max.train_and_evaluate(train_data_loader, test_data_loader, n_epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(list_train_loss, list_train_acc, list_test_loss, list_test_acc, n_epochs=100, title='GCN (Aggregation=Max)')"
      ],
      "metadata": {
        "id": "IUcEKhrQWYMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aggregation Function = Min"
      ],
      "metadata": {
        "id": "jKQMuIJoWh3h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q12EFCO3WYZR"
      },
      "outputs": [],
      "source": [
        "model = GCN_Add_Pooling(hidden_channels=64, aggregation='mean')\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_GCN_min = Leaning_Evaluation(\n",
        "                                   model = model,\n",
        "                                   best_results=[0, 0, 0]\n",
        "                                   )\n",
        "list_train_acc, list_train_loss, list_test_acc, list_test_loss = evaluate_GCN_min.train_and_evaluate(train_data_loader, test_data_loader, n_epochs=100)"
      ],
      "metadata": {
        "id": "W2lD5nkkWYZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(list_train_loss, list_train_acc, list_test_loss, list_test_acc, n_epochs=100, title='GCN (Aggregation=mean)')"
      ],
      "metadata": {
        "id": "aeQbn77HWYZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aggregation Function = [Add, Max, Min]"
      ],
      "metadata": {
        "id": "9oLavqRpsfqV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9e8A4cT8sdvm"
      },
      "outputs": [],
      "source": [
        "model = GCN_Add_Pooling(hidden_channels=8, aggregation=['add','mean','max'])\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_GCN_min = Leaning_Evaluation(\n",
        "                                   model = model,\n",
        "                                   )\n",
        "list_train_acc, list_train_loss, list_test_acc, list_test_loss = evaluate_GCN_min.train_and_evaluate(train_data_loader, test_data_loader, n_epochs=100)"
      ],
      "metadata": {
        "id": "wCfkoEnssdvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(list_train_loss, list_train_acc, list_test_loss, list_test_acc, n_epochs=100, title='GCN (Aggregation=[add, mean, max])')"
      ],
      "metadata": {
        "id": "Wk-4gq6Lsdvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GraphSage"
      ],
      "metadata": {
        "id": "bCs6xjTZlUNQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJwLIWmnlUNf"
      },
      "outputs": [],
      "source": [
        "model = Graph_Sage(hidden_channels=64)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_GraphSage = Leaning_Evaluation(\n",
        "                                   model = model,\n",
        "                                   learning_rate=0.006,\n",
        "                                   best_results=[0, 0, 0]\n",
        "                                   )\n",
        "list_train_acc, list_train_loss, list_test_acc, list_test_loss = evaluate_GraphSage.train_and_evaluate(train_data_loader, test_data_loader, n_epochs=150)"
      ],
      "metadata": {
        "id": "xTDqCl8ZlUNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(list_train_loss, list_train_acc, list_test_loss, list_test_acc, n_epochs=150, title='GraphSage')"
      ],
      "metadata": {
        "id": "mCR553jLlUNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GraphConv"
      ],
      "metadata": {
        "id": "KoqgMyOzlVGj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1rzFFRalVGj"
      },
      "outputs": [],
      "source": [
        "model = Graph_Conv(hidden_channels=64)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_GraphConv = Leaning_Evaluation(\n",
        "                                   model = model,\n",
        "                                   learning_rate=0.001,\n",
        "                                   best_results=[0, 0, 0]\n",
        "                                   )\n",
        "list_train_acc, list_train_loss, list_test_acc, list_test_loss = evaluate_GraphConv.train_and_evaluate(train_data_loader, test_data_loader,  n_epochs=150)"
      ],
      "metadata": {
        "id": "uowACngClVGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(list_train_loss, list_train_acc, list_test_loss, list_test_acc, n_epochs=150, title='GraphConv')"
      ],
      "metadata": {
        "id": "mJ18-rE7lVGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "conclusion = pd.DataFrame([['GCN (Mean polling)' ,0.8933, 0.7368, 165],\n",
        "              ['GCN (Max polling)',0.8933, 0.7368, 165],\n",
        "              ['GCN (Add polling)',0.8867, 0.7895, 165],\n",
        "              ['GraphSage (Add polling)',0.8667, 0.8421, 182],\n",
        "              ['GraphConv (Add polling)',0.9533, 0.8947, 192]],\n",
        "              columns=[\"Model Details\",\"Train Accuracy\",\"Test Accuracy\",'Epoch with best result'])\n",
        "conclusion = conclusion.set_index('Model Details')\n",
        "conclusion.style.background_gradient(cmap=\"YlOrRd\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ZpZVBk1cllCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dCfNa4Esyhp3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMdfkBFsylQNhCFXsl2q3u",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}